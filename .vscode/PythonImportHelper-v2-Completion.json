[
    {
        "label": "numpy",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "numpy",
        "description": "numpy",
        "detail": "numpy",
        "documentation": {}
    },
    {
        "label": "pandas",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "pandas",
        "description": "pandas",
        "detail": "pandas",
        "documentation": {}
    },
    {
        "label": "sklearn",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "sklearn",
        "description": "sklearn",
        "detail": "sklearn",
        "documentation": {}
    },
    {
        "label": "datasets",
        "importPath": "sklearn",
        "description": "sklearn",
        "isExtraImport": true,
        "detail": "sklearn",
        "documentation": {}
    },
    {
        "label": "defaultdict",
        "importPath": "collections",
        "description": "collections",
        "isExtraImport": true,
        "detail": "collections",
        "documentation": {}
    },
    {
        "label": "Counter",
        "importPath": "collections",
        "description": "collections",
        "isExtraImport": true,
        "detail": "collections",
        "documentation": {}
    },
    {
        "label": "math",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "math",
        "description": "math",
        "detail": "math",
        "documentation": {}
    },
    {
        "label": "random",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "random",
        "description": "random",
        "detail": "random",
        "documentation": {}
    },
    {
        "label": "OneHotEncoder",
        "importPath": "sklearn.preprocessing",
        "description": "sklearn.preprocessing",
        "isExtraImport": true,
        "detail": "sklearn.preprocessing",
        "documentation": {}
    },
    {
        "label": "OneHotEncoder",
        "importPath": "sklearn.preprocessing",
        "description": "sklearn.preprocessing",
        "isExtraImport": true,
        "detail": "sklearn.preprocessing",
        "documentation": {}
    },
    {
        "label": "OneHotEncoder",
        "importPath": "sklearn.preprocessing",
        "description": "sklearn.preprocessing",
        "isExtraImport": true,
        "detail": "sklearn.preprocessing",
        "documentation": {}
    },
    {
        "label": "matplotlib.pyplot",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "matplotlib.pyplot",
        "description": "matplotlib.pyplot",
        "detail": "matplotlib.pyplot",
        "documentation": {}
    },
    {
        "label": "re",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "re",
        "description": "re",
        "detail": "re",
        "documentation": {}
    },
    {
        "label": "os",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "os",
        "description": "os",
        "detail": "os",
        "documentation": {}
    },
    {
        "label": "sys",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "sys",
        "description": "sys",
        "detail": "sys",
        "documentation": {}
    },
    {
        "label": "os,sys",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "os.sys",
        "description": "os.sys",
        "detail": "os.sys",
        "documentation": {}
    },
    {
        "label": "backpropagation_vectorized",
        "importPath": "propagation",
        "description": "propagation",
        "isExtraImport": true,
        "detail": "propagation",
        "documentation": {}
    },
    {
        "label": "forward_propagation",
        "importPath": "propagation",
        "description": "propagation",
        "isExtraImport": true,
        "detail": "propagation",
        "documentation": {}
    },
    {
        "label": "cost_function",
        "importPath": "propagation",
        "description": "propagation",
        "isExtraImport": true,
        "detail": "propagation",
        "documentation": {}
    },
    {
        "label": "debug_text",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "debug_text",
        "description": "debug_text",
        "detail": "debug_text",
        "documentation": {}
    },
    {
        "label": "json",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "json",
        "description": "json",
        "detail": "json",
        "documentation": {}
    },
    {
        "label": "load_dataset",
        "kind": 2,
        "importPath": "datasets.load_digits",
        "description": "datasets.load_digits",
        "peekOfCode": "def load_dataset():\n    # Load the digits dataset (0â€“9)\n    digits = datasets.load_digits()\n    X = pd.DataFrame(digits.data)\n    print(X)\n    y = pd.Series(digits.target)\n    # Add target to the dataframe\n    X['label'] = y\n    X = X.dropna(axis=1, how='all')                 # drop all-NaN columns\n    X = X.loc[:, ~(X == 0).all()]                  # drop all-0 columns",
        "detail": "datasets.load_digits",
        "documentation": {}
    },
    {
        "label": "stratified_k_fold_split",
        "kind": 2,
        "importPath": "ensemble_algorithm.en",
        "description": "ensemble_algorithm.en",
        "peekOfCode": "def stratified_k_fold_split(X, y, k):\n    df = pd.DataFrame(X)\n    df['label'] = y.ravel()\n    df['original_index'] = np.arange(len(df))\n    class_0 = df[df['label'] == 0].sample(frac=1).reset_index(drop=True)\n    class_1 = df[df['label'] == 1].sample(frac=1).reset_index(drop=True)\n    folds = []\n    for i in range(k):\n        c0 = class_0.iloc[int(len(class_0)*i/k):int(len(class_0)*(i+1)/k)]\n        c1 = class_1.iloc[int(len(class_1)*i/k):int(len(class_1)*(i+1)/k)]",
        "detail": "ensemble_algorithm.en",
        "documentation": {}
    },
    {
        "label": "load_dataset",
        "kind": 2,
        "importPath": "ensemble_algorithm.en",
        "description": "ensemble_algorithm.en",
        "peekOfCode": "def load_dataset(DATASET_NAME):\n    # Load dataset from CSV file\n    df = pd.read_csv(f\"../datasets/{DATASET_NAME}.csv\")\n    # === parkinsons --> customize datset ===\n    if DATASET_NAME==\"parkinsons\":\n        # change last column as label\n        df.rename(columns={\"Diagnosis\": \"label\"}, inplace=True)\n    elif DATASET_NAME==\"rice\":\n        df[\"label\"] = df[\"label\"].astype(\"category\").cat.codes\n    # Use 'diagnosis' column if 'label' doesn't exist",
        "detail": "ensemble_algorithm.en",
        "documentation": {}
    },
    {
        "label": "normalize_train_test",
        "kind": 2,
        "importPath": "ensemble_algorithm.en",
        "description": "ensemble_algorithm.en",
        "peekOfCode": "def normalize_train_test(train_df, test_df):\n    features = train_df.drop(columns=['label', 'original_index']).columns\n    train_X = train_df[features]\n    test_X = test_df[features]\n    min_vals = train_X.min()\n    max_vals = train_X.max()\n    diff = max_vals - min_vals\n    diff[diff == 0] = 1e-8\n    train_X_norm = (train_X - min_vals) / diff\n    test_X_norm = (test_X - min_vals) / diff",
        "detail": "ensemble_algorithm.en",
        "documentation": {}
    },
    {
        "label": "majority_vote",
        "kind": 2,
        "importPath": "ensemble_algorithm.en",
        "description": "ensemble_algorithm.en",
        "peekOfCode": "def majority_vote(votes):\n    return Counter(votes).most_common(1)[0][0]\n# === KNN Fold Runner ===\ndef run_knn_single_fold(X_train, y_train, X_test, k=KNN_NEAREST_K):\n    def euclidean(x1, x2):\n        return np.sqrt(np.sum((x1 - x2) ** 2))\n    def majority_vote(neighbors):\n        count = Counter(neighbors)\n        return count.most_common(1)[0][0]\n    predictions = []",
        "detail": "ensemble_algorithm.en",
        "documentation": {}
    },
    {
        "label": "run_knn_single_fold",
        "kind": 2,
        "importPath": "ensemble_algorithm.en",
        "description": "ensemble_algorithm.en",
        "peekOfCode": "def run_knn_single_fold(X_train, y_train, X_test, k=KNN_NEAREST_K):\n    def euclidean(x1, x2):\n        return np.sqrt(np.sum((x1 - x2) ** 2))\n    def majority_vote(neighbors):\n        count = Counter(neighbors)\n        return count.most_common(1)[0][0]\n    predictions = []\n    for test_point in X_test:\n        distances = [euclidean(test_point, x_train) for x_train in X_train]\n        neighbors_idx = np.argsort(distances)[:k]",
        "detail": "ensemble_algorithm.en",
        "documentation": {}
    },
    {
        "label": "run_tree_single_fold",
        "kind": 2,
        "importPath": "ensemble_algorithm.en",
        "description": "ensemble_algorithm.en",
        "peekOfCode": "def run_tree_single_fold(X_train, y_train, X_test, ntrees=NTREES):\n    class Node:\n        def __init__(self, feature=None, threshold=None, label=None, children=None):\n            self.feature = feature\n            self.threshold = threshold\n            self.label = label\n            self.children = children if children else {}\n    def entropy(y):\n        probabilities = y.value_counts() / len(y)\n        return -np.sum(probabilities * np.log2(probabilities))",
        "detail": "ensemble_algorithm.en",
        "documentation": {}
    },
    {
        "label": "run_nn_single_fold",
        "kind": 2,
        "importPath": "ensemble_algorithm.en",
        "description": "ensemble_algorithm.en",
        "peekOfCode": "def run_nn_single_fold(X_train, y_train, X_test):\n    class NeuralNetwork:\n        def __init__(self, layer_sizes, alpha=0.01, lambda_reg=0.0):\n            self.layer_sizes = layer_sizes\n            self.alpha = alpha\n            self.lambda_reg = lambda_reg\n            self.weights = self.initialize_weights()\n        def initialize_weights(self):\n            weights = []\n            for i in range(len(self.layer_sizes) - 1):",
        "detail": "ensemble_algorithm.en",
        "documentation": {}
    },
    {
        "label": "my_accuracy",
        "kind": 2,
        "importPath": "ensemble_algorithm.en",
        "description": "ensemble_algorithm.en",
        "peekOfCode": "def my_accuracy(y_true, y_pred):\n    correct = np.sum(np.array(y_true) == np.array(y_pred))\n    return correct / len(y_true)\n# === F1 Score Calculation ===\ndef my_f1_score(y_true, y_pred):\n    y_true = np.array(y_true)\n    y_pred = np.array(y_pred)\n    tp = np.sum((y_true == 1) & (y_pred == 1))\n    fp = np.sum((y_true == 0) & (y_pred == 1))\n    fn = np.sum((y_true == 1) & (y_pred == 0))",
        "detail": "ensemble_algorithm.en",
        "documentation": {}
    },
    {
        "label": "my_f1_score",
        "kind": 2,
        "importPath": "ensemble_algorithm.en",
        "description": "ensemble_algorithm.en",
        "peekOfCode": "def my_f1_score(y_true, y_pred):\n    y_true = np.array(y_true)\n    y_pred = np.array(y_pred)\n    tp = np.sum((y_true == 1) & (y_pred == 1))\n    fp = np.sum((y_true == 0) & (y_pred == 1))\n    fn = np.sum((y_true == 1) & (y_pred == 0))\n    if tp == 0:\n        return 0.0\n    precision = tp / (tp + fp) if (tp + fp) > 0 else 0.0\n    recall = tp / (tp + fn) if (tp + fn) > 0 else 0.0",
        "detail": "ensemble_algorithm.en",
        "documentation": {}
    },
    {
        "label": "ensemble_main",
        "kind": 2,
        "importPath": "ensemble_algorithm.en",
        "description": "ensemble_algorithm.en",
        "peekOfCode": "def ensemble_main(DATASET_NAME):\n    X, y = load_dataset(DATASET_NAME)\n    folds = stratified_k_fold_split(X, y, K_FOLD_SIZE)\n    vote_dict = defaultdict(list)\n    for fold_idx, (train_df, test_df) in enumerate(folds):\n        print(f\"\\nðŸ” Fold {fold_idx+1}/{K_FOLD_SIZE}\")\n        train_df, test_df = normalize_train_test(train_df, test_df)\n        X_train = train_df.drop(columns=['label']).values\n        y_train = train_df['label'].values.ravel()\n        X_test = test_df.drop(columns=['label']).values",
        "detail": "ensemble_algorithm.en",
        "documentation": {}
    },
    {
        "label": "K_FOLD_SIZE",
        "kind": 5,
        "importPath": "ensemble_algorithm.en",
        "description": "ensemble_algorithm.en",
        "peekOfCode": "K_FOLD_SIZE = 10\nKNN_NEAREST_K=5\nNTREES=40\nMAX_DEPTH=5\nMIN_INFO_GAIN=0.00001\nHIDDEN_LAYER = [64] \nALPHA=0.1\nLAMBDA_REG=1e-6\nBATCH_SIZE=64\nM_SIZE=50",
        "detail": "ensemble_algorithm.en",
        "documentation": {}
    },
    {
        "label": "HIDDEN_LAYER",
        "kind": 5,
        "importPath": "ensemble_algorithm.en",
        "description": "ensemble_algorithm.en",
        "peekOfCode": "HIDDEN_LAYER = [64] \nALPHA=0.1\nLAMBDA_REG=1e-6\nBATCH_SIZE=64\nM_SIZE=50\n# === Stratified K-Fold Split Function ===\ndef stratified_k_fold_split(X, y, k):\n    df = pd.DataFrame(X)\n    df['label'] = y.ravel()\n    df['original_index'] = np.arange(len(df))",
        "detail": "ensemble_algorithm.en",
        "documentation": {}
    },
    {
        "label": "load_data",
        "kind": 2,
        "importPath": "knn_algorithm.knn",
        "description": "knn_algorithm.knn",
        "peekOfCode": "def load_data(DATASET_NAME):\n    data_file = pd.read_csv(f'../datasets/{DATASET_NAME}.csv', header=None)\n    if DATASET_NAME == \"parkinsons\":\n        data_file.rename(columns={\"Diagnosis\": \"label\"}, inplace=True)\n    elif DATASET_NAME==\"rice\":\n        data_file[\"label\"] = data_file[\"label\"].astype(\"category\").cat.codes\n    data_file = data_file.apply(pd.to_numeric, errors='coerce')\n    data_file = data_file.drop(index=0).reset_index(drop=True)\n    return data_file\n# === Stratified K-Fold Split ===",
        "detail": "knn_algorithm.knn",
        "documentation": {}
    },
    {
        "label": "stratified_k_fold_split",
        "kind": 2,
        "importPath": "knn_algorithm.knn",
        "description": "knn_algorithm.knn",
        "peekOfCode": "def stratified_k_fold_split(X, y, k):\n    df = pd.DataFrame(X)\n    df['label'] = y\n    class_0 = df[df['label'] == 0].sample(frac=1).reset_index(drop=True)\n    class_1 = df[df['label'] == 1].sample(frac=1).reset_index(drop=True)\n    folds = []\n    for i in range(k):\n        c0 = class_0.iloc[int(len(class_0)*i/k):int(len(class_0)*(i+1)/k)]\n        c1 = class_1.iloc[int(len(class_1)*i/k):int(len(class_1)*(i+1)/k)]\n        test_df = pd.concat([c0, c1]).sample(frac=1).reset_index(drop=True)",
        "detail": "knn_algorithm.knn",
        "documentation": {}
    },
    {
        "label": "attribute_class",
        "kind": 2,
        "importPath": "knn_algorithm.knn",
        "description": "knn_algorithm.knn",
        "peekOfCode": "def attribute_class(data):\n    attribute_data = data.iloc[:, :-1]\n    class_data = data.iloc[:, -1]\n    return attribute_data, class_data\n# === Normalize data using Min-Max ===\ndef normalization_formula_train(train_data):\n    min_vals = np.min(train_data.to_numpy(), axis=0)\n    max_vals = np.max(train_data.to_numpy(), axis=0)\n    diff = max_vals - min_vals\n    if np.all(diff == 0):",
        "detail": "knn_algorithm.knn",
        "documentation": {}
    },
    {
        "label": "normalization_formula_train",
        "kind": 2,
        "importPath": "knn_algorithm.knn",
        "description": "knn_algorithm.knn",
        "peekOfCode": "def normalization_formula_train(train_data):\n    min_vals = np.min(train_data.to_numpy(), axis=0)\n    max_vals = np.max(train_data.to_numpy(), axis=0)\n    diff = max_vals - min_vals\n    if np.all(diff == 0):\n        print(\"Zero-variance columns:\", np.where(diff == 0))\n    normalized_train = (train_data - min_vals) / diff\n    return pd.DataFrame(normalized_train, columns=train_data.columns), min_vals, diff\ndef normalization_formula_test(test_data, min_vals, diff):\n    normalized_test = (test_data - min_vals) / diff",
        "detail": "knn_algorithm.knn",
        "documentation": {}
    },
    {
        "label": "normalization_formula_test",
        "kind": 2,
        "importPath": "knn_algorithm.knn",
        "description": "knn_algorithm.knn",
        "peekOfCode": "def normalization_formula_test(test_data, min_vals, diff):\n    normalized_test = (test_data - min_vals) / diff\n    return pd.DataFrame(normalized_test, columns=test_data.columns)\n# === Euclidean distance calculation ===\ndef euclidean_formula(vector1, vector2):\n    return np.sqrt(np.sum((vector1 - vector2) ** 2))\ndef euclidean_matrix(train_data, test_data, data_info):\n    euclidean_table = np.zeros((len(train_data), len(test_data)))\n    for train_idx in range(len(train_data)):\n        for test_idx in range(len(test_data)):",
        "detail": "knn_algorithm.knn",
        "documentation": {}
    },
    {
        "label": "euclidean_formula",
        "kind": 2,
        "importPath": "knn_algorithm.knn",
        "description": "knn_algorithm.knn",
        "peekOfCode": "def euclidean_formula(vector1, vector2):\n    return np.sqrt(np.sum((vector1 - vector2) ** 2))\ndef euclidean_matrix(train_data, test_data, data_info):\n    euclidean_table = np.zeros((len(train_data), len(test_data)))\n    for train_idx in range(len(train_data)):\n        for test_idx in range(len(test_data)):\n            euclidean_table[train_idx, test_idx] = euclidean_formula(train_data.iloc[train_idx], test_data.iloc[test_idx])\n    euclidean_df = pd.DataFrame(euclidean_table, index=[f\"Train_{i}\" for i in range(len(train_data))], columns=[f\"Test_{j}\" for j in range(len(test_data))])\n    print(\"--> Euclidean distance matrix has been created : \" + data_info + \"_data...\")\n    return euclidean_df",
        "detail": "knn_algorithm.knn",
        "documentation": {}
    },
    {
        "label": "euclidean_matrix",
        "kind": 2,
        "importPath": "knn_algorithm.knn",
        "description": "knn_algorithm.knn",
        "peekOfCode": "def euclidean_matrix(train_data, test_data, data_info):\n    euclidean_table = np.zeros((len(train_data), len(test_data)))\n    for train_idx in range(len(train_data)):\n        for test_idx in range(len(test_data)):\n            euclidean_table[train_idx, test_idx] = euclidean_formula(train_data.iloc[train_idx], test_data.iloc[test_idx])\n    euclidean_df = pd.DataFrame(euclidean_table, index=[f\"Train_{i}\" for i in range(len(train_data))], columns=[f\"Test_{j}\" for j in range(len(test_data))])\n    print(\"--> Euclidean distance matrix has been created : \" + data_info + \"_data...\")\n    return euclidean_df\n# === Select k-nearest neighbors ===\ndef cutoff_k(test_column, k_num):",
        "detail": "knn_algorithm.knn",
        "documentation": {}
    },
    {
        "label": "cutoff_k",
        "kind": 2,
        "importPath": "knn_algorithm.knn",
        "description": "knn_algorithm.knn",
        "peekOfCode": "def cutoff_k(test_column, k_num):\n    smallest_column = test_column.sort_values(ascending=True)[:k_num]\n    smallest_indices = smallest_column.index.str.split('_').str[1].astype(int)\n    return smallest_indices\n# === Determine majority label ===\ndef majority_formula(list):\n    count_1 = list.value_counts().get(1, 0)\n    count_0 = list.value_counts().get(0, 0)\n    return 1 if count_1 > count_0 else 0\n# === Accuracy calculation ===",
        "detail": "knn_algorithm.knn",
        "documentation": {}
    },
    {
        "label": "majority_formula",
        "kind": 2,
        "importPath": "knn_algorithm.knn",
        "description": "knn_algorithm.knn",
        "peekOfCode": "def majority_formula(list):\n    count_1 = list.value_counts().get(1, 0)\n    count_0 = list.value_counts().get(0, 0)\n    return 1 if count_1 > count_0 else 0\n# === Accuracy calculation ===\ndef calculate_accuracy(actual_series, predicted_series):\n    actual_list = np.array(actual_series.tolist())\n    predicted_list = np.array(predicted_series, dtype=int)\n    match_count = np.sum(actual_list == predicted_list)\n    return match_count / len(actual_list)",
        "detail": "knn_algorithm.knn",
        "documentation": {}
    },
    {
        "label": "calculate_accuracy",
        "kind": 2,
        "importPath": "knn_algorithm.knn",
        "description": "knn_algorithm.knn",
        "peekOfCode": "def calculate_accuracy(actual_series, predicted_series):\n    actual_list = np.array(actual_series.tolist())\n    predicted_list = np.array(predicted_series, dtype=int)\n    match_count = np.sum(actual_list == predicted_list)\n    return match_count / len(actual_list)\n# === F1 Score calculation ===\ndef calculate_f1score(actual_series, predicted_series):\n    actual = np.array(actual_series.tolist(), dtype=int)\n    predicted = np.array(predicted_series.tolist(), dtype=int)\n    TP = np.sum((actual == 1) & (predicted == 1))",
        "detail": "knn_algorithm.knn",
        "documentation": {}
    },
    {
        "label": "calculate_f1score",
        "kind": 2,
        "importPath": "knn_algorithm.knn",
        "description": "knn_algorithm.knn",
        "peekOfCode": "def calculate_f1score(actual_series, predicted_series):\n    actual = np.array(actual_series.tolist(), dtype=int)\n    predicted = np.array(predicted_series.tolist(), dtype=int)\n    TP = np.sum((actual == 1) & (predicted == 1))\n    FP = np.sum((actual == 0) & (predicted == 1))\n    FN = np.sum((actual == 1) & (predicted == 0))\n    precision = TP / (TP + FP) if (TP + FP) > 0 else 0\n    recall = TP / (TP + FN) if (TP + FN) > 0 else 0\n    return 2 * precision * recall / (precision + recall) if precision + recall > 0 else 0.0\n# === Run KNN for given k values ===",
        "detail": "knn_algorithm.knn",
        "documentation": {}
    },
    {
        "label": "knn_algorithm",
        "kind": 2,
        "importPath": "knn_algorithm.knn",
        "description": "knn_algorithm.knn",
        "peekOfCode": "def knn_algorithm(k, test_euclidean, predicted_class, actual_class, data_info, fold_count, accuracy_f1_table):\n    predicted_table = pd.DataFrame()\n    for k_num in range(1, k+1, 2):\n        for test_num in range(len(test_euclidean.columns)):\n            cutoff_indices = cutoff_k(test_euclidean[f\"Test_{test_num}\"], k_num)\n            predicted_list = predicted_class.iloc[cutoff_indices]\n            predicted_value = majority_formula(predicted_list)\n            predicted_table.at[f\"Test_{test_num}\", f\"k={k_num}\"] = int(predicted_value)\n            print(f\"knn algorithm : test_data={data_info} , fold={fold_count} , k={k_num} , test_instance={test_num}\")\n        accuracy_value = calculate_accuracy(actual_class, predicted_table[f\"k={k_num}\"])",
        "detail": "knn_algorithm.knn",
        "documentation": {}
    },
    {
        "label": "accuracy_avg_std",
        "kind": 2,
        "importPath": "knn_algorithm.knn",
        "description": "knn_algorithm.knn",
        "peekOfCode": "def accuracy_avg_std(accuracy_f1_table, data_info):\n    meanstd = accuracy_f1_table.agg(['mean', 'std'])\n    graph_table = pd.concat([accuracy_f1_table, meanstd])\n    print(\"\\n--> Calculate mean and standard deviation of each k value : \" + str(data_info) + \"...\")\n    return graph_table\n# === Draw accuracy graph with error bars ===\ndef draw_graph(accuracy_f1_table, title):\n    accuracy_table = accuracy_f1_table[[col for col in accuracy_f1_table.columns if \"accuracy\" in col]]\n    k_values = [int(re.search(r'\\(k=(\\d+)\\)', col).group(1)) for col in accuracy_table.columns]\n    mean_values = accuracy_table.loc['mean'].tolist()",
        "detail": "knn_algorithm.knn",
        "documentation": {}
    },
    {
        "label": "draw_graph",
        "kind": 2,
        "importPath": "knn_algorithm.knn",
        "description": "knn_algorithm.knn",
        "peekOfCode": "def draw_graph(accuracy_f1_table, title):\n    accuracy_table = accuracy_f1_table[[col for col in accuracy_f1_table.columns if \"accuracy\" in col]]\n    k_values = [int(re.search(r'\\(k=(\\d+)\\)', col).group(1)) for col in accuracy_table.columns]\n    mean_values = accuracy_table.loc['mean'].tolist()\n    std_values = accuracy_table.loc['std'].tolist()\n    plt.figure(figsize=(6, 4))\n    plt.errorbar(k_values, mean_values, yerr=std_values, fmt='o-', capsize=5)\n    plt.xlabel(\"(Value of k)\")\n    plt.ylabel(\"(Accuracy over \" + title + \" data\")\n    plt.savefig(f'evaluation/{DATASET_NAME}_' + title + \".png\", dpi=300, bbox_inches='tight')",
        "detail": "knn_algorithm.knn",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "knn_algorithm.knn",
        "description": "knn_algorithm.knn",
        "peekOfCode": "def main(DATASET_NAME):\n    # if the folder is not existed, create one\n    os.makedirs(\"evaluation\", exist_ok=True) \n    os.makedirs(\"normalization\", exist_ok=True) \n    data_file = load_data(DATASET_NAME)\n    attributes, labels = attribute_class(data_file)\n    folds = stratified_k_fold_split(attributes, labels, K_FOLD_SIZE)\n    train_accuracy = pd.DataFrame()\n    test_accuracy = pd.DataFrame()\n    for fold_count, (train_df, test_df) in enumerate(folds, start=1):",
        "detail": "knn_algorithm.knn",
        "documentation": {}
    },
    {
        "label": "my_accuracy",
        "kind": 2,
        "importPath": "linear_regression.reg",
        "description": "linear_regression.reg",
        "peekOfCode": "def my_accuracy(y_true, y_pred):\n    correct = np.sum(y_true.flatten() == y_pred.flatten())\n    return correct / len(y_true)\n# === Macro F1 Score Calculation for Multiclass ===\ndef my_f1_score(y_true, y_pred):\n    labels = np.unique(y_true)\n    f1_scores = []\n    for label in labels:\n        tp = np.sum((y_true == label) & (y_pred == label))\n        fp = np.sum((y_true != label) & (y_pred == label))",
        "detail": "linear_regression.reg",
        "documentation": {}
    },
    {
        "label": "my_f1_score",
        "kind": 2,
        "importPath": "linear_regression.reg",
        "description": "linear_regression.reg",
        "peekOfCode": "def my_f1_score(y_true, y_pred):\n    labels = np.unique(y_true)\n    f1_scores = []\n    for label in labels:\n        tp = np.sum((y_true == label) & (y_pred == label))\n        fp = np.sum((y_true != label) & (y_pred == label))\n        fn = np.sum((y_true == label) & (y_pred != label))\n        precision = tp / (tp + fp) if (tp + fp) > 0 else 0.0\n        recall = tp / (tp + fn) if (tp + fn) > 0 else 0.0\n        f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0.0",
        "detail": "linear_regression.reg",
        "documentation": {}
    },
    {
        "label": "load_dataset",
        "kind": 2,
        "importPath": "linear_regression.reg",
        "description": "linear_regression.reg",
        "peekOfCode": "def load_dataset(DATASET_NAME):\n    df = pd.read_csv(f\"../datasets/{DATASET_NAME}.csv\")\n    if DATASET_NAME == \"parkinsons\":\n        df.rename(columns={\"Diagnosis\": \"label\"}, inplace=True)\n    elif DATASET_NAME == \"rice\":\n        df[\"label\"] = df[\"label\"].astype(\"category\").cat.codes\n    if 'label' not in df.columns:\n        raise ValueError(\"Dataset must contain a 'label' column.\")\n    y = df['label'].copy()\n    X = df.drop(columns=['label'])",
        "detail": "linear_regression.reg",
        "documentation": {}
    },
    {
        "label": "normalize_by_train",
        "kind": 2,
        "importPath": "linear_regression.reg",
        "description": "linear_regression.reg",
        "peekOfCode": "def normalize_by_train(X_train_df, X_test_df):\n    X_train = X_train_df.copy()\n    X_test = X_test_df.copy()\n    for col in X_train.columns:\n        if col.endswith(\"_num\"):\n            mean = X_train[col].mean()\n            std = X_train[col].std()\n            X_train[col] = (X_train[col] - mean) / std\n            X_test[col] = (X_test[col] - mean) / std\n        elif col.endswith(\"_cat\"):",
        "detail": "linear_regression.reg",
        "documentation": {}
    },
    {
        "label": "stratified_k_fold_split",
        "kind": 2,
        "importPath": "linear_regression.reg",
        "description": "linear_regression.reg",
        "peekOfCode": "def stratified_k_fold_split(X, y, k):\n    df = X.copy()\n    df['label'] = y.ravel()\n    folds = []\n    for i in range(k):\n        test_df = df.iloc[i::k]\n        train_df = df.drop(test_df.index)\n        folds.append((train_df.reset_index(drop=True), test_df.reset_index(drop=True)))\n    return folds\n# === Train Multinomial Linear Regression model ===",
        "detail": "linear_regression.reg",
        "documentation": {}
    },
    {
        "label": "train_multinomial_linear",
        "kind": 2,
        "importPath": "linear_regression.reg",
        "description": "linear_regression.reg",
        "peekOfCode": "def train_multinomial_linear(X, y, num_classes, lr=0.0001, epochs=1000, epsilon=1e-6):\n    n_samples, n_features = X.shape\n    W = np.zeros((n_features, num_classes))\n    b = np.zeros((num_classes,))\n    Y_onehot = np.eye(num_classes)[y.reshape(-1)]\n    prev_loss = float('inf')\n    for epoch in range(epochs):\n        logits = np.dot(X, W) + b\n        error = logits - Y_onehot\n        error = np.clip(error, -1e3, 1e3)  # overflow ë°©ì§€",
        "detail": "linear_regression.reg",
        "documentation": {}
    },
    {
        "label": "predict_linear",
        "kind": 2,
        "importPath": "linear_regression.reg",
        "description": "linear_regression.reg",
        "peekOfCode": "def predict_linear(X, W, b):\n    logits = np.dot(X, W) + b\n    return np.argmax(logits, axis=1)\n# === Evaluation with K-Fold Cross-Validation ===\ndef evaluate_multinomial_linear(DATASET_NAME, K_FOLD=5):\n    X_df, y = load_dataset(DATASET_NAME)\n    folds = stratified_k_fold_split(X_df, y, K_FOLD)\n    acc_list, f1_list = [], []\n    for i, (train_df, test_df) in enumerate(folds):\n        y_train = train_df[\"label\"].values.reshape(-1, 1)",
        "detail": "linear_regression.reg",
        "documentation": {}
    },
    {
        "label": "evaluate_multinomial_linear",
        "kind": 2,
        "importPath": "linear_regression.reg",
        "description": "linear_regression.reg",
        "peekOfCode": "def evaluate_multinomial_linear(DATASET_NAME, K_FOLD=5):\n    X_df, y = load_dataset(DATASET_NAME)\n    folds = stratified_k_fold_split(X_df, y, K_FOLD)\n    acc_list, f1_list = [], []\n    for i, (train_df, test_df) in enumerate(folds):\n        y_train = train_df[\"label\"].values.reshape(-1, 1)\n        y_test = test_df[\"label\"].values.reshape(-1, 1)\n        X_train_df = train_df.drop(columns=[\"label\"])\n        X_test_df = test_df.drop(columns=[\"label\"])\n        X_train_df, X_test_df = normalize_by_train(X_train_df, X_test_df)",
        "detail": "linear_regression.reg",
        "documentation": {}
    },
    {
        "label": "K_FOLD_SIZE",
        "kind": 5,
        "importPath": "linear_regression.reg",
        "description": "linear_regression.reg",
        "peekOfCode": "K_FOLD_SIZE = 10\n# === Accuracy Calculation ===\ndef my_accuracy(y_true, y_pred):\n    correct = np.sum(y_true.flatten() == y_pred.flatten())\n    return correct / len(y_true)\n# === Macro F1 Score Calculation for Multiclass ===\ndef my_f1_score(y_true, y_pred):\n    labels = np.unique(y_true)\n    f1_scores = []\n    for label in labels:",
        "detail": "linear_regression.reg",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "neural_network.debug_text",
        "description": "neural_network.debug_text",
        "peekOfCode": "def main(lambda_reg, X, y, Theta, all_a_lists, all_z_lists, J_list, final_cost, delta_list, D_list, finalized_D, DEBUG_FILENAME, header=\"\"): \n    # if the folder is not existed, create\n    os.makedirs(\"debug\", exist_ok=True) \n    # Open a debug file for writing results\n    with open(f\"debug/backprop_{DEBUG_FILENAME}.txt\", \"w\", encoding=\"utf-8\") as f:\n        if header:\n            # Write optional header if provided\n            f.write(\"=\" * 80 + \"\\n\")\n            f.write(header + \"\\n\")\n            f.write(\"=\" * 80 + \"\\n\")",
        "detail": "neural_network.debug_text",
        "documentation": {}
    },
    {
        "label": "NeuralNetwork",
        "kind": 6,
        "importPath": "neural_network.nn",
        "description": "neural_network.nn",
        "peekOfCode": "class NeuralNetwork:\n    def __init__(self, layer_sizes, alpha=0.01, lambda_reg=0.0):\n        self.layer_sizes = layer_sizes  # Architecture of the network\n        self.alpha = alpha              # Learning rate\n        self.lambda_reg = lambda_reg    # Regularization parameter\n        self.weights = self.initialize_weights()  # Random weight initialization\n        self.cost_history = []          # Store J value per training set\n    def initialize_weights(self):\n        # Initialize weights for each layer using uniform distribution\n        weights = []",
        "detail": "neural_network.nn",
        "documentation": {}
    },
    {
        "label": "load_dataset",
        "kind": 2,
        "importPath": "neural_network.nn",
        "description": "neural_network.nn",
        "peekOfCode": "def load_dataset(DATASET_NAME):\n    # Load dataset from CSV file\n    df = pd.read_csv(f\"../datasets/{DATASET_NAME}.csv\")\n    # === parkinsons --> customize datset ===\n    if DATASET_NAME==\"parkinsons\":\n        # change last column as label\n        df.rename(columns={\"Diagnosis\": \"label\"}, inplace=True)\n    elif DATASET_NAME==\"rice\":\n        df[\"label\"] = df[\"label\"].astype(\"category\").cat.codes\n    # Use 'diagnosis' column if 'label' doesn't exist",
        "detail": "neural_network.nn",
        "documentation": {}
    },
    {
        "label": "stratified_k_fold_split",
        "kind": 2,
        "importPath": "neural_network.nn",
        "description": "neural_network.nn",
        "peekOfCode": "def stratified_k_fold_split(X, y, k):\n    # Create stratified folds with equal class distribution\n    df = pd.DataFrame(X)\n    df['label'] = y.ravel()\n    class_0 = df[df['label'] == 0].sample(frac=1).reset_index(drop=True)\n    class_1 = df[df['label'] == 1].sample(frac=1).reset_index(drop=True)\n    folds = []\n    for i in range(k):\n        c0 = class_0.iloc[int(len(class_0)*i/k):int(len(class_0)*(i+1)/k)]\n        c1 = class_1.iloc[int(len(class_1)*i/k):int(len(class_1)*(i+1)/k)]",
        "detail": "neural_network.nn",
        "documentation": {}
    },
    {
        "label": "my_accuracy",
        "kind": 2,
        "importPath": "neural_network.nn",
        "description": "neural_network.nn",
        "peekOfCode": "def my_accuracy(y_true, y_pred):\n    correct = np.sum(y_true == y_pred)\n    return correct / len(y_true)\n# === F1 Score Calculation ===\ndef my_f1_score(y_true, y_pred):\n    tp = np.sum((y_true == 1) & (y_pred == 1))\n    fp = np.sum((y_true == 0) & (y_pred == 1))\n    fn = np.sum((y_true == 1) & (y_pred == 0))\n    if tp == 0:\n        return 0.0",
        "detail": "neural_network.nn",
        "documentation": {}
    },
    {
        "label": "my_f1_score",
        "kind": 2,
        "importPath": "neural_network.nn",
        "description": "neural_network.nn",
        "peekOfCode": "def my_f1_score(y_true, y_pred):\n    tp = np.sum((y_true == 1) & (y_pred == 1))\n    fp = np.sum((y_true == 0) & (y_pred == 1))\n    fn = np.sum((y_true == 1) & (y_pred == 0))\n    if tp == 0:\n        return 0.0\n    precision = tp / (tp + fp) if (tp + fp) > 0 else 0.0\n    recall = tp / (tp + fn) if (tp + fn) > 0 else 0.0\n    if precision + recall == 0:\n        return 0.0",
        "detail": "neural_network.nn",
        "documentation": {}
    },
    {
        "label": "info_text",
        "kind": 2,
        "importPath": "neural_network.nn",
        "description": "neural_network.nn",
        "peekOfCode": "def info_text(lambda_reg,hidden_layer,alpha,mode, batch_size, DATASET_NAME):\n    info = f\"{DATASET_NAME.capitalize()} BEST Learning Curve\\n Î»={lambda_reg},  Hidden={hidden_layer}, \\nÎ±={alpha}, Mode={mode}\"\n    if mode == \"mini-batch\":\n        info += f\", Batch Size={batch_size}\\n\"\n    else:\n        info += f\"\\n\"\n    if STOP_CRITERIA==\"M\":\n        info += f\"Stopping Criteria=m size [{M_SIZE}]\"   \n    elif STOP_CRITERIA==\"J\":\n        info += f\"Stopping Criteria=Final Cost(J)[{J_SIZE}]\"   ",
        "detail": "neural_network.nn",
        "documentation": {}
    },
    {
        "label": "plot_best_learning_curve",
        "kind": 2,
        "importPath": "neural_network.nn",
        "description": "neural_network.nn",
        "peekOfCode": "def plot_best_learning_curve(results, save_folder, DATASET_NAME):\n    # Identify model with lowest final cost\n    best_key = min(results, key=lambda k: results[k]['model'].cost_history[-1])\n    best_info = results[best_key]\n    model = best_info['model']\n    hidden_layer = best_info['hidden']\n    lambda_reg = best_info['lambda_reg']\n    train_size = best_info['train_size']\n    alpha = best_info['alpha']\n    mode = best_info['mode']",
        "detail": "neural_network.nn",
        "documentation": {}
    },
    {
        "label": "save_metrics_table",
        "kind": 2,
        "importPath": "neural_network.nn",
        "description": "neural_network.nn",
        "peekOfCode": "def save_metrics_table(results, save_folder, DATASET_NAME):\n    os.makedirs(\"evaluation\", exist_ok=True)\n    fig, ax = plt.subplots(figsize=(10, 8))\n    ax.axis('off')\n    # Determine table columns based on whether mini-batch was used\n    if any(val['mode'] == 'mini-batch' for val in results.values()):\n        col_labels = [\"Layer & Neuron\", \"Lambda\", \"Alpha\", \"Batch Size\", \"Mode\", \"Avg Accuracy\", \"Avg F1 Score\"]\n        show_batch_size = True\n    else:\n        col_labels = [\"Layer & Neuron\", \"Lambda\", \"Alpha\", \"Mode\", \"Avg Accuracy\", \"Avg F1 Score\"]",
        "detail": "neural_network.nn",
        "documentation": {}
    },
    {
        "label": "neural_network",
        "kind": 2,
        "importPath": "neural_network.nn",
        "description": "neural_network.nn",
        "peekOfCode": "def neural_network(DATASET_NAME):\n    # if the folder is not existed, create\n    os.makedirs(\"evaluation\", exist_ok=True) \n    X, y = load_dataset(DATASET_NAME)  # Load data and labels\n    folds = stratified_k_fold_split(X, y, k=K_FOLD_SIZE)  # Create 10-fold split\n    lambda_reg_list = LAMBDA_REG  # List of Î» values to test\n    hidden_layers = HIDDEN_LAYER  # Layer architectures to test\n    alpha = ALPHA            # Learning rate\n    batch_size = BATCH_SIZE        # Size of mini-batches\n    mode = TRAIN_MODE        # Training mode",
        "detail": "neural_network.nn",
        "documentation": {}
    },
    {
        "label": "DATASET_NAME",
        "kind": 5,
        "importPath": "neural_network.nn",
        "description": "neural_network.nn",
        "peekOfCode": "DATASET_NAME = \"credit_approval\"  # Name of the dataset\nK_FOLD_SIZE= 10\nDEBUG_MODE = True         # If True, run debugging routine at the end\nTRAIN_MODE = \"mini-batch\"    # Choose \"batch\" or \"mini-batch\"\nBATCH_SIZE = 256\nALPHA=0.1\n# === Stopping Criteria ===\nSTOP_CRITERIA = \"M\"\nM_SIZE = 2000            \nJ_SIZE=0.1",
        "detail": "neural_network.nn",
        "documentation": {}
    },
    {
        "label": "DEBUG_MODE",
        "kind": 5,
        "importPath": "neural_network.nn",
        "description": "neural_network.nn",
        "peekOfCode": "DEBUG_MODE = True         # If True, run debugging routine at the end\nTRAIN_MODE = \"mini-batch\"    # Choose \"batch\" or \"mini-batch\"\nBATCH_SIZE = 256\nALPHA=0.1\n# === Stopping Criteria ===\nSTOP_CRITERIA = \"M\"\nM_SIZE = 2000            \nJ_SIZE=0.1\n# === Hyper Parameter ===\n#LAMBDA_REG=[0.000001]",
        "detail": "neural_network.nn",
        "documentation": {}
    },
    {
        "label": "TRAIN_MODE",
        "kind": 5,
        "importPath": "neural_network.nn",
        "description": "neural_network.nn",
        "peekOfCode": "TRAIN_MODE = \"mini-batch\"    # Choose \"batch\" or \"mini-batch\"\nBATCH_SIZE = 256\nALPHA=0.1\n# === Stopping Criteria ===\nSTOP_CRITERIA = \"M\"\nM_SIZE = 2000            \nJ_SIZE=0.1\n# === Hyper Parameter ===\n#LAMBDA_REG=[0.000001]\n#HIDDEN_LAYER=[[64,32,16,8]]",
        "detail": "neural_network.nn",
        "documentation": {}
    },
    {
        "label": "BATCH_SIZE",
        "kind": 5,
        "importPath": "neural_network.nn",
        "description": "neural_network.nn",
        "peekOfCode": "BATCH_SIZE = 256\nALPHA=0.1\n# === Stopping Criteria ===\nSTOP_CRITERIA = \"M\"\nM_SIZE = 2000            \nJ_SIZE=0.1\n# === Hyper Parameter ===\n#LAMBDA_REG=[0.000001]\n#HIDDEN_LAYER=[[64,32,16,8]]\nLAMBDA_REG=[0.1, 0.001, 0.000001]",
        "detail": "neural_network.nn",
        "documentation": {}
    },
    {
        "label": "STOP_CRITERIA",
        "kind": 5,
        "importPath": "neural_network.nn",
        "description": "neural_network.nn",
        "peekOfCode": "STOP_CRITERIA = \"M\"\nM_SIZE = 2000            \nJ_SIZE=0.1\n# === Hyper Parameter ===\n#LAMBDA_REG=[0.000001]\n#HIDDEN_LAYER=[[64,32,16,8]]\nLAMBDA_REG=[0.1, 0.001, 0.000001]\nHIDDEN_LAYER=[[64,32,16,8,4],[64,32,16,8],[64,32,16],[64,32],[64],[32]]\n# parkinsons\n# LAMBDA_REG=[5, 1, 0.5, 0.1]",
        "detail": "neural_network.nn",
        "documentation": {}
    },
    {
        "label": "M_SIZE",
        "kind": 5,
        "importPath": "neural_network.nn",
        "description": "neural_network.nn",
        "peekOfCode": "M_SIZE = 2000            \nJ_SIZE=0.1\n# === Hyper Parameter ===\n#LAMBDA_REG=[0.000001]\n#HIDDEN_LAYER=[[64,32,16,8]]\nLAMBDA_REG=[0.1, 0.001, 0.000001]\nHIDDEN_LAYER=[[64,32,16,8,4],[64,32,16,8],[64,32,16],[64,32],[64],[32]]\n# parkinsons\n# LAMBDA_REG=[5, 1, 0.5, 0.1]\n# HIDDEN_LAYER=[[22, 64, 64, 32, 1],[22, 64, 32, 1],[22, 32, 1]]",
        "detail": "neural_network.nn",
        "documentation": {}
    },
    {
        "label": "sigmoid",
        "kind": 2,
        "importPath": "neural_network.propagation",
        "description": "neural_network.propagation",
        "peekOfCode": "def sigmoid(z):\n    return 1 / (1 + np.exp(-z))\ndef sigmoid_gradient(z):\n    return sigmoid(z) * (1 - sigmoid(z))\ndef add_bias(X):\n    return np.concatenate([np.ones((X.shape[0], 1)), X], axis=1)\ndef forward_propagation(Theta, X):\n    Theta = [np.array(t) for t in Theta]\n    A = [add_bias(np.array(X))] \n    Z = []",
        "detail": "neural_network.propagation",
        "documentation": {}
    },
    {
        "label": "sigmoid_gradient",
        "kind": 2,
        "importPath": "neural_network.propagation",
        "description": "neural_network.propagation",
        "peekOfCode": "def sigmoid_gradient(z):\n    return sigmoid(z) * (1 - sigmoid(z))\ndef add_bias(X):\n    return np.concatenate([np.ones((X.shape[0], 1)), X], axis=1)\ndef forward_propagation(Theta, X):\n    Theta = [np.array(t) for t in Theta]\n    A = [add_bias(np.array(X))] \n    Z = []\n    for i, Theta_i in enumerate(Theta):\n        Z_i = A[-1] @ Theta_i.T",
        "detail": "neural_network.propagation",
        "documentation": {}
    },
    {
        "label": "add_bias",
        "kind": 2,
        "importPath": "neural_network.propagation",
        "description": "neural_network.propagation",
        "peekOfCode": "def add_bias(X):\n    return np.concatenate([np.ones((X.shape[0], 1)), X], axis=1)\ndef forward_propagation(Theta, X):\n    Theta = [np.array(t) for t in Theta]\n    A = [add_bias(np.array(X))] \n    Z = []\n    for i, Theta_i in enumerate(Theta):\n        Z_i = A[-1] @ Theta_i.T\n        A_i = sigmoid(Z_i)\n        Z.append(Z_i)",
        "detail": "neural_network.propagation",
        "documentation": {}
    },
    {
        "label": "forward_propagation",
        "kind": 2,
        "importPath": "neural_network.propagation",
        "description": "neural_network.propagation",
        "peekOfCode": "def forward_propagation(Theta, X):\n    Theta = [np.array(t) for t in Theta]\n    A = [add_bias(np.array(X))] \n    Z = []\n    for i, Theta_i in enumerate(Theta):\n        Z_i = A[-1] @ Theta_i.T\n        A_i = sigmoid(Z_i)\n        Z.append(Z_i)\n        if i < len(Theta) - 1:\n            A_i = add_bias(A_i) # add bias in hidden layer only",
        "detail": "neural_network.propagation",
        "documentation": {}
    },
    {
        "label": "cost_function",
        "kind": 2,
        "importPath": "neural_network.propagation",
        "description": "neural_network.propagation",
        "peekOfCode": "def cost_function(A_final, Y, Theta, lambda_reg):\n    m = Y.shape[0]\n    cost = -np.sum(Y * np.log(A_final) + (1 - Y) * np.log(1 - A_final)) / m\n    reg_term = 0\n    for theta in Theta:\n        theta = np.array(theta)\n        # remove bias -> [:, 1:]\n        reg_term += np.sum(theta[:, 1:] ** 2) \n    reg_term = reg_term * (lambda_reg / (2 * m))\n    return cost, cost + reg_term",
        "detail": "neural_network.propagation",
        "documentation": {}
    },
    {
        "label": "backpropagation_vectorized",
        "kind": 2,
        "importPath": "neural_network.propagation",
        "description": "neural_network.propagation",
        "peekOfCode": "def backpropagation_vectorized(Theta, A, Z, Y, lambda_reg):\n    Theta = [np.array(t) for t in Theta]\n    m = Y.shape[0]\n    delta = A[-1] - Y\n    gradients = [None] * len(Theta)\n    for i in reversed(range(len(Theta))):\n        a_prev = A[i]\n        gradients[i] = (delta.T @ a_prev) / m\n        if i > 0:\n            delta = (delta @ Theta[i][:, 1:]) * sigmoid_gradient(Z[i - 1])",
        "detail": "neural_network.propagation",
        "documentation": {}
    },
    {
        "label": "run_debug",
        "kind": 2,
        "importPath": "neural_network.propagation",
        "description": "neural_network.propagation",
        "peekOfCode": "def run_debug(Theta, X, y, lambda_reg, DEBUG_FILENAME):\n    np.set_printoptions(precision=5, suppress=True, floatmode='fixed')\n    A, Z, all_a_lists, all_z_lists = forward_propagation(Theta, X)\n    pred_y_list = [a_list[-1] for a_list in all_a_lists]\n    true_y_list = [y[i].reshape(-1, 1) for i in range(y.shape[0])]\n    J_list = []\n    for pred, true in zip(pred_y_list, true_y_list):\n        J = -(true.T @ np.log(pred) + (1 - true).T @ np.log(1 - pred))\n        J_list.append(J.item())\n    delta_list = []",
        "detail": "neural_network.propagation",
        "documentation": {}
    },
    {
        "label": "Node",
        "kind": 6,
        "importPath": "random_forest.tree",
        "description": "random_forest.tree",
        "peekOfCode": "class Node:\n    def __init__(self, feature=None, threshold=None, label=None, children=None):\n        self.feature = feature\n        self.threshold = threshold\n        self.label = label\n        self.children = children if children else {}\ndef entropy(y):\n    probabilities = y.value_counts() / len(y)\n    return -np.sum(probabilities * np.log2(probabilities))\ndef build_tree(X, y, features, depth=0):",
        "detail": "random_forest.tree",
        "documentation": {}
    },
    {
        "label": "load_and_preprocess_data",
        "kind": 2,
        "importPath": "random_forest.tree",
        "description": "random_forest.tree",
        "peekOfCode": "def load_and_preprocess_data(DATASET_NAME):\n    data = pd.read_csv(f\"../datasets/{DATASET_NAME}.csv\")\n    data = data.rename(columns={\"class\": \"label\"})\n    if DATASET_NAME == \"parkinsons\":\n        data.rename(columns={\"Diagnosis\": \"label\"}, inplace=True)\n    elif DATASET_NAME==\"rice\":\n        data[\"label\"] = data[\"label\"].astype(\"category\").cat.codes\n    for col in data.columns:\n        if col == \"label\":\n            continue",
        "detail": "random_forest.tree",
        "documentation": {}
    },
    {
        "label": "cross_validation",
        "kind": 2,
        "importPath": "random_forest.tree",
        "description": "random_forest.tree",
        "peekOfCode": "def cross_validation(data, k_fold):\n    class_0 = data[data['label'] == 0].sample(frac=1).reset_index(drop=True)\n    class_1 = data[data['label'] == 1].sample(frac=1).reset_index(drop=True)\n    all_data = pd.DataFrame()\n    for i in range(k_fold):\n        class_0_fold = class_0.iloc[int(len(class_0)*i/k_fold):int(len(class_0)*(i+1)/k_fold)]\n        class_1_fold = class_1.iloc[int(len(class_1)*i/k_fold):int(len(class_1)*(i+1)/k_fold)]\n        fold_data = pd.concat([class_0_fold, class_1_fold]).copy()\n        fold_data[\"k_fold\"] = i\n        all_data = pd.concat([all_data, fold_data], ignore_index=True)",
        "detail": "random_forest.tree",
        "documentation": {}
    },
    {
        "label": "bootstrap_sample",
        "kind": 2,
        "importPath": "random_forest.tree",
        "description": "random_forest.tree",
        "peekOfCode": "def bootstrap_sample(X, y):\n    idxs = np.random.choice(len(X), size=len(X), replace=True)\n    return X.iloc[idxs].reset_index(drop=True), y.iloc[idxs].reset_index(drop=True)\ndef main(DATASET_NAME):\n    os.makedirs(\"plot\", exist_ok=True)\n    os.makedirs(\"table\", exist_ok=True)\n    data = load_and_preprocess_data(DATASET_NAME)\n    fold_data = cross_validation(data, k_fold=K_FOLD_SIZE)\n    ntrees_list, metrics, predict_y = evaluate_random_forest(fold_data, K_FOLD_SIZE, DATASET_NAME)\n    plot_metrics(ntrees_list, metrics, DATASET_NAME)",
        "detail": "random_forest.tree",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "random_forest.tree",
        "description": "random_forest.tree",
        "peekOfCode": "def main(DATASET_NAME):\n    os.makedirs(\"plot\", exist_ok=True)\n    os.makedirs(\"table\", exist_ok=True)\n    data = load_and_preprocess_data(DATASET_NAME)\n    fold_data = cross_validation(data, k_fold=K_FOLD_SIZE)\n    ntrees_list, metrics, predict_y = evaluate_random_forest(fold_data, K_FOLD_SIZE, DATASET_NAME)\n    plot_metrics(ntrees_list, metrics, DATASET_NAME)\n    return predict_y\ndef evaluate_random_forest(fold_data, k_fold, DATASET_NAME):\n    ntrees_list = [1, 5, 10, 20, 30, 40, 50]",
        "detail": "random_forest.tree",
        "documentation": {}
    },
    {
        "label": "evaluate_random_forest",
        "kind": 2,
        "importPath": "random_forest.tree",
        "description": "random_forest.tree",
        "peekOfCode": "def evaluate_random_forest(fold_data, k_fold, DATASET_NAME):\n    ntrees_list = [1, 5, 10, 20, 30, 40, 50]\n    acc_list, prec_list, rec_list, f1_list = [], [], [], []\n    final_predictions = None\n    for ntrees in ntrees_list:\n        print(f\"\\nEvaluating Random Forest with {ntrees} trees\")\n        accs, precisions, recalls, f1s = [], [], [], []\n        for i in range(k_fold):\n            test_data = fold_data[fold_data[\"k_fold\"] == i]\n            train_data = fold_data[fold_data[\"k_fold\"] != i]",
        "detail": "random_forest.tree",
        "documentation": {}
    },
    {
        "label": "entropy",
        "kind": 2,
        "importPath": "random_forest.tree",
        "description": "random_forest.tree",
        "peekOfCode": "def entropy(y):\n    probabilities = y.value_counts() / len(y)\n    return -np.sum(probabilities * np.log2(probabilities))\ndef build_tree(X, y, features, depth=0):\n    if len(y.unique()) == 1 or len(features) == 0 or depth == MAX_DEPTH:\n        return Node(label=y.mode()[0])\n    m = int(math.sqrt(len(features)))\n    selected_features = random.sample(list(features), m)\n    best_feature, best_gain, best_threshold = None, -1, None\n    for feature in selected_features:",
        "detail": "random_forest.tree",
        "documentation": {}
    },
    {
        "label": "build_tree",
        "kind": 2,
        "importPath": "random_forest.tree",
        "description": "random_forest.tree",
        "peekOfCode": "def build_tree(X, y, features, depth=0):\n    if len(y.unique()) == 1 or len(features) == 0 or depth == MAX_DEPTH:\n        return Node(label=y.mode()[0])\n    m = int(math.sqrt(len(features)))\n    selected_features = random.sample(list(features), m)\n    best_feature, best_gain, best_threshold = None, -1, None\n    for feature in selected_features:\n        if feature.endswith('_cat'):\n            values = X[feature].unique()\n            weighted_entropy = sum((len(y[X[feature] == v]) / len(y)) * entropy(y[X[feature] == v]) for v in values)",
        "detail": "random_forest.tree",
        "documentation": {}
    },
    {
        "label": "random_forest_predict",
        "kind": 2,
        "importPath": "random_forest.tree",
        "description": "random_forest.tree",
        "peekOfCode": "def random_forest_predict(trees, X_test):\n    tree_preds = np.array([predict(tree, X_test) for tree in trees])\n    final_preds = []\n    for i in range(X_test.shape[0]):\n        row_preds = tree_preds[:, i]\n        values, counts = np.unique(row_preds[row_preds != None], return_counts=True)\n        if len(counts) == 0:\n            final_preds.append(None)\n        elif len(counts) > 1 and counts[0] == counts[1]:\n            final_preds.append(random.choice(values))",
        "detail": "random_forest.tree",
        "documentation": {}
    },
    {
        "label": "predict",
        "kind": 2,
        "importPath": "random_forest.tree",
        "description": "random_forest.tree",
        "peekOfCode": "def predict(tree, X_test):\n    predictions = []\n    for _, row in X_test.iterrows():\n        node = tree\n        while node.label is None:\n            val = row[node.feature]\n            if node.threshold is None:\n                node = node.children.get(val)\n            else:\n                node = node.children.get(\"<=\") if val <= node.threshold else node.children.get(\">\")",
        "detail": "random_forest.tree",
        "documentation": {}
    },
    {
        "label": "accuracy",
        "kind": 2,
        "importPath": "random_forest.tree",
        "description": "random_forest.tree",
        "peekOfCode": "def accuracy(predictions, true_labels):\n    predictions, true_labels = np.array(predictions), np.array(true_labels)\n    valid = predictions != None\n    return np.mean(predictions[valid] == true_labels[valid])\ndef precision(y_true, y_pred):\n    tp = np.sum((y_pred == 1) & (y_true == 1))\n    fp = np.sum((y_pred == 1) & (y_true == 0))\n    return tp / (tp + fp) if (tp + fp) > 0 else 0.0\ndef recall(y_true, y_pred):\n    tp = np.sum((y_pred == 1) & (y_true == 1))",
        "detail": "random_forest.tree",
        "documentation": {}
    },
    {
        "label": "precision",
        "kind": 2,
        "importPath": "random_forest.tree",
        "description": "random_forest.tree",
        "peekOfCode": "def precision(y_true, y_pred):\n    tp = np.sum((y_pred == 1) & (y_true == 1))\n    fp = np.sum((y_pred == 1) & (y_true == 0))\n    return tp / (tp + fp) if (tp + fp) > 0 else 0.0\ndef recall(y_true, y_pred):\n    tp = np.sum((y_pred == 1) & (y_true == 1))\n    fn = np.sum((y_pred == 0) & (y_true == 1))\n    return tp / (tp + fn) if (tp + fn) > 0 else 0.0\ndef f1_score_manual(y_true, y_pred):\n    p = precision(y_true, y_pred)",
        "detail": "random_forest.tree",
        "documentation": {}
    },
    {
        "label": "recall",
        "kind": 2,
        "importPath": "random_forest.tree",
        "description": "random_forest.tree",
        "peekOfCode": "def recall(y_true, y_pred):\n    tp = np.sum((y_pred == 1) & (y_true == 1))\n    fn = np.sum((y_pred == 0) & (y_true == 1))\n    return tp / (tp + fn) if (tp + fn) > 0 else 0.0\ndef f1_score_manual(y_true, y_pred):\n    p = precision(y_true, y_pred)\n    r = recall(y_true, y_pred)\n    return 2 * p * r / (p + r) if (p + r) > 0 else 0.0\ndef plot_metrics(ntrees_list, metrics, DATASET_NAME):\n    titles = [\"Accuracy\", \"Precision\", \"Recall\", \"F1Score\"]",
        "detail": "random_forest.tree",
        "documentation": {}
    },
    {
        "label": "f1_score_manual",
        "kind": 2,
        "importPath": "random_forest.tree",
        "description": "random_forest.tree",
        "peekOfCode": "def f1_score_manual(y_true, y_pred):\n    p = precision(y_true, y_pred)\n    r = recall(y_true, y_pred)\n    return 2 * p * r / (p + r) if (p + r) > 0 else 0.0\ndef plot_metrics(ntrees_list, metrics, DATASET_NAME):\n    titles = [\"Accuracy\", \"Precision\", \"Recall\", \"F1Score\"]\n    for metric, title in zip(metrics, titles):\n        plt.figure(figsize=(6, 4))\n        plt.plot(ntrees_list, metric, marker='o')\n        plt.title(f\"{DATASET_NAME.capitalize()} Dataset_{title} vs ntrees\")",
        "detail": "random_forest.tree",
        "documentation": {}
    },
    {
        "label": "plot_metrics",
        "kind": 2,
        "importPath": "random_forest.tree",
        "description": "random_forest.tree",
        "peekOfCode": "def plot_metrics(ntrees_list, metrics, DATASET_NAME):\n    titles = [\"Accuracy\", \"Precision\", \"Recall\", \"F1Score\"]\n    for metric, title in zip(metrics, titles):\n        plt.figure(figsize=(6, 4))\n        plt.plot(ntrees_list, metric, marker='o')\n        plt.title(f\"{DATASET_NAME.capitalize()} Dataset_{title} vs ntrees\")\n        plt.xlabel(\"ntrees\")\n        plt.ylabel(title)\n        plt.grid(True)\n        plt.savefig(f\"plot/{DATASET_NAME}_{title}.png\")",
        "detail": "random_forest.tree",
        "documentation": {}
    },
    {
        "label": "tree_to_dict",
        "kind": 2,
        "importPath": "random_forest.tree",
        "description": "random_forest.tree",
        "peekOfCode": "def tree_to_dict(node):\n    if node.label is not None:\n        return {\"label\": int(node.label)}\n    return {\n        \"feature\": node.feature,\n        \"threshold\": node.threshold,\n        \"children\": {str(k): tree_to_dict(v) for k, v in node.children.items()}\n    }\ndef save_trees_as_json(trees, ntrees, base_dir=\"saved_trees\"):\n    folder = os.path.join(base_dir, f\"ntrees_{ntrees}\")",
        "detail": "random_forest.tree",
        "documentation": {}
    },
    {
        "label": "save_trees_as_json",
        "kind": 2,
        "importPath": "random_forest.tree",
        "description": "random_forest.tree",
        "peekOfCode": "def save_trees_as_json(trees, ntrees, base_dir=\"saved_trees\"):\n    folder = os.path.join(base_dir, f\"ntrees_{ntrees}\")\n    os.makedirs(folder, exist_ok=True)\n    for i, tree in enumerate(trees, start=1):\n        tree_dict = tree_to_dict(tree)\n        with open(os.path.join(folder, f\"tree_{i}.json\"), \"w\") as f:\n            json.dump(tree_dict, f, indent=4)\nif __name__ == \"__main__\":\n    main(DATASET_NAME=DATASET_NAME)",
        "detail": "random_forest.tree",
        "documentation": {}
    },
    {
        "label": "MAX_DEPTH",
        "kind": 5,
        "importPath": "random_forest.tree",
        "description": "random_forest.tree",
        "peekOfCode": "MAX_DEPTH = 5\nMIN_INFO_GAIN = 1e-5\n# ===== Preprocessing =====\ndef load_and_preprocess_data(DATASET_NAME):\n    data = pd.read_csv(f\"../datasets/{DATASET_NAME}.csv\")\n    data = data.rename(columns={\"class\": \"label\"})\n    if DATASET_NAME == \"parkinsons\":\n        data.rename(columns={\"Diagnosis\": \"label\"}, inplace=True)\n    elif DATASET_NAME==\"rice\":\n        data[\"label\"] = data[\"label\"].astype(\"category\").cat.codes",
        "detail": "random_forest.tree",
        "documentation": {}
    },
    {
        "label": "MIN_INFO_GAIN",
        "kind": 5,
        "importPath": "random_forest.tree",
        "description": "random_forest.tree",
        "peekOfCode": "MIN_INFO_GAIN = 1e-5\n# ===== Preprocessing =====\ndef load_and_preprocess_data(DATASET_NAME):\n    data = pd.read_csv(f\"../datasets/{DATASET_NAME}.csv\")\n    data = data.rename(columns={\"class\": \"label\"})\n    if DATASET_NAME == \"parkinsons\":\n        data.rename(columns={\"Diagnosis\": \"label\"}, inplace=True)\n    elif DATASET_NAME==\"rice\":\n        data[\"label\"] = data[\"label\"].astype(\"category\").cat.codes\n    for col in data.columns:",
        "detail": "random_forest.tree",
        "documentation": {}
    }
]