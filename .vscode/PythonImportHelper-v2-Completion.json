[
    {
        "label": "pandas",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "pandas",
        "description": "pandas",
        "detail": "pandas",
        "documentation": {}
    },
    {
        "label": "numpy",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "numpy",
        "description": "numpy",
        "detail": "numpy",
        "documentation": {}
    },
    {
        "label": "sklearn",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "sklearn",
        "description": "sklearn",
        "detail": "sklearn",
        "documentation": {}
    },
    {
        "label": "datasets",
        "importPath": "sklearn",
        "description": "sklearn",
        "isExtraImport": true,
        "detail": "sklearn",
        "documentation": {}
    },
    {
        "label": "datasets",
        "importPath": "sklearn",
        "description": "sklearn",
        "isExtraImport": true,
        "detail": "sklearn",
        "documentation": {}
    },
    {
        "label": "matplotlib.pyplot",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "matplotlib.pyplot",
        "description": "matplotlib.pyplot",
        "detail": "matplotlib.pyplot",
        "documentation": {}
    },
    {
        "label": "re",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "re",
        "description": "re",
        "detail": "re",
        "documentation": {}
    },
    {
        "label": "os",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "os",
        "description": "os",
        "detail": "os",
        "documentation": {}
    },
    {
        "label": "OneHotEncoder",
        "importPath": "sklearn.preprocessing",
        "description": "sklearn.preprocessing",
        "isExtraImport": true,
        "detail": "sklearn.preprocessing",
        "documentation": {}
    },
    {
        "label": "backpropagation_vectorized",
        "importPath": "propagation",
        "description": "propagation",
        "isExtraImport": true,
        "detail": "propagation",
        "documentation": {}
    },
    {
        "label": "forward_propagation",
        "importPath": "propagation",
        "description": "propagation",
        "isExtraImport": true,
        "detail": "propagation",
        "documentation": {}
    },
    {
        "label": "cost_function",
        "importPath": "propagation",
        "description": "propagation",
        "isExtraImport": true,
        "detail": "propagation",
        "documentation": {}
    },
    {
        "label": "debug_text",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "debug_text",
        "description": "debug_text",
        "detail": "debug_text",
        "documentation": {}
    },
    {
        "label": "json",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "json",
        "description": "json",
        "detail": "json",
        "documentation": {}
    },
    {
        "label": "math",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "math",
        "description": "math",
        "detail": "math",
        "documentation": {}
    },
    {
        "label": "random",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "random",
        "description": "random",
        "detail": "random",
        "documentation": {}
    },
    {
        "label": "train_test_split",
        "importPath": "sklearn.model_selection",
        "description": "sklearn.model_selection",
        "isExtraImport": true,
        "detail": "sklearn.model_selection",
        "documentation": {}
    },
    {
        "label": "shuffle",
        "importPath": "sklearn.utils",
        "description": "sklearn.utils",
        "isExtraImport": true,
        "detail": "sklearn.utils",
        "documentation": {}
    },
    {
        "label": "df",
        "kind": 5,
        "importPath": "datasets.label_parkinsons",
        "description": "datasets.label_parkinsons",
        "peekOfCode": "df = pd.read_csv(\"parkinsons.csv\")\n# ë§ˆì§€ë§‰ ì—´ ì´ë¦„ì„ 'label'ë¡œ ë³€ê²½\ndf.rename(columns={df.columns[-1]: \"label\"}, inplace=True)\n# ë³€ê²½ëœ ê²°ê³¼ë¥¼ ë‹¤ì‹œ CSVë¡œ ì €ìž¥\ndf.to_csv(\"parkinsons_labeled.csv\", index=False)",
        "detail": "datasets.label_parkinsons",
        "documentation": {}
    },
    {
        "label": "load_dataset",
        "kind": 2,
        "importPath": "datasets.load_digits",
        "description": "datasets.load_digits",
        "peekOfCode": "def load_dataset():\n    # Load the digits dataset (0â€“9)\n    digits = datasets.load_digits()\n    X = pd.DataFrame(digits.data)\n    print(X)\n    y = pd.Series(digits.target)\n    # Add target to the dataframe\n    X['label'] = y\n    X = X.dropna(axis=1, how='all')                 # drop all-NaN columns\n    X = X.loc[:, ~(X == 0).all()]                  # drop all-0 columns",
        "detail": "datasets.load_digits",
        "documentation": {}
    },
    {
        "label": "attribute_class",
        "kind": 2,
        "importPath": "knn_algorithm.knn",
        "description": "knn_algorithm.knn",
        "peekOfCode": "def attribute_class(data):\n    # separate attributes and class\n    attribute_data=data.iloc[:,:-1]\n    class_data=data.iloc[:, -1]\n    return attribute_data, class_data\ndef normalization_forumla(data):\n    data_numpy=data.to_numpy()\n    normalized_numpy = (data_numpy - np.min(data_numpy, axis=0)) / (np.max(data_numpy, axis=0) - np.min(data_numpy, axis=0))\n    #check which one is the problem\n    diff = np.max(data_numpy, axis=0) - np.min(data_numpy, axis=0)",
        "detail": "knn_algorithm.knn",
        "documentation": {}
    },
    {
        "label": "normalization_forumla",
        "kind": 2,
        "importPath": "knn_algorithm.knn",
        "description": "knn_algorithm.knn",
        "peekOfCode": "def normalization_forumla(data):\n    data_numpy=data.to_numpy()\n    normalized_numpy = (data_numpy - np.min(data_numpy, axis=0)) / (np.max(data_numpy, axis=0) - np.min(data_numpy, axis=0))\n    #check which one is the problem\n    diff = np.max(data_numpy, axis=0) - np.min(data_numpy, axis=0)\n    print(\"Zero-variance columns (same value for all rows):\", np.where(diff == 0))\n    # change normalized data to pandas dataframe\n    normalized_data = pd.DataFrame(normalized_numpy, columns=data.columns)\n    return normalized_data\ndef load_data():",
        "detail": "knn_algorithm.knn",
        "documentation": {}
    },
    {
        "label": "load_data",
        "kind": 2,
        "importPath": "knn_algorithm.knn",
        "description": "knn_algorithm.knn",
        "peekOfCode": "def load_data():\n    # read CSV file\n    data_file = pd.read_csv(f'../datasets/{DATASET_NAME}.csv', header=None)\n    # if you have columnn -> maybe recognize as string\n    data_file = data_file.apply(pd.to_numeric, errors='coerce')\n    # attribute become another row -> need to remove\n    data_file=data_file.drop(index=0)\n    data_file=data_file.reset_index(drop=True)\n    return data_file\n# Prepared train_data, test_data",
        "detail": "knn_algorithm.knn",
        "documentation": {}
    },
    {
        "label": "shuffle_normalization",
        "kind": 2,
        "importPath": "knn_algorithm.knn",
        "description": "knn_algorithm.knn",
        "peekOfCode": "def shuffle_normalization(data_file):\n    # shuffle the DataFrame\n    shuffled_data = sk.utils.shuffle(data_file)\n    # split data with training and testing\n    train_data, test_data= sk.model_selection.train_test_split(shuffled_data, test_size=0.2)\n    # reset index both train_data and test_data\n    train_data=train_data.reset_index(drop=True)\n    test_data=test_data.reset_index(drop=True)\n    #train_data.to_excel('train_data.xlsx')\n    #test_data.to_excel('test_data.xlsx')",
        "detail": "knn_algorithm.knn",
        "documentation": {}
    },
    {
        "label": "euclidean_formula",
        "kind": 2,
        "importPath": "knn_algorithm.knn",
        "description": "knn_algorithm.knn",
        "peekOfCode": "def euclidean_formula(vector1,vector2):\n    # follow eucliean distance formula\n    euclidean_distance = np.sqrt(np.sum((vector1-vector2)**2))\n    return euclidean_distance\n# Calculate Euclidean Distane in train_data\ndef euclidean_matrix(train_data, test_data, data_info):\n    # Initialize an empty NumPy array (rows = train_data, columns = test_data)\n    euclidean_table = np.zeros((len(train_data), len(test_data)))\n    # Compute distances row-wise (train_data as rows, test_data as columns)\n    for train_idx in range(len(train_data)):",
        "detail": "knn_algorithm.knn",
        "documentation": {}
    },
    {
        "label": "euclidean_matrix",
        "kind": 2,
        "importPath": "knn_algorithm.knn",
        "description": "knn_algorithm.knn",
        "peekOfCode": "def euclidean_matrix(train_data, test_data, data_info):\n    # Initialize an empty NumPy array (rows = train_data, columns = test_data)\n    euclidean_table = np.zeros((len(train_data), len(test_data)))\n    # Compute distances row-wise (train_data as rows, test_data as columns)\n    for train_idx in range(len(train_data)):\n        for test_idx in range(len(test_data)):\n            euclidean_table[train_idx, test_idx] = euclidean_formula(\n                train_data.iloc[train_idx], test_data.iloc[test_idx]\n            )\n    # Convert the NumPy array to a DataFrame (train_data as index, test_data as columns)",
        "detail": "knn_algorithm.knn",
        "documentation": {}
    },
    {
        "label": "cutoff_k",
        "kind": 2,
        "importPath": "knn_algorithm.knn",
        "description": "knn_algorithm.knn",
        "peekOfCode": "def cutoff_k(test_column,k_num):\n    # sort by smallest and cutoff k amount\n    smallest_column=test_column.sort_values(ascending=True)[:k_num]\n    # find index of smallest_column\n    smallest_indices=smallest_column.index.str.split('_').str[1].astype(int)\n    return smallest_indices\n# check majority\ndef majority_formula(list):\n    # count 1 or 0, if there is nothing value is 0\n    count_1 = list.value_counts().get(1, 0)  ",
        "detail": "knn_algorithm.knn",
        "documentation": {}
    },
    {
        "label": "majority_formula",
        "kind": 2,
        "importPath": "knn_algorithm.knn",
        "description": "knn_algorithm.knn",
        "peekOfCode": "def majority_formula(list):\n    # count 1 or 0, if there is nothing value is 0\n    count_1 = list.value_counts().get(1, 0)  \n    count_0 = list.value_counts().get(0, 0) \n    # betwen 1 and 0 which one is more\n    if count_1 > count_0:\n        return 1\n    else:\n        return 0\n# Accuracy in Training and Testing",
        "detail": "knn_algorithm.knn",
        "documentation": {}
    },
    {
        "label": "calculate_accuracy",
        "kind": 2,
        "importPath": "knn_algorithm.knn",
        "description": "knn_algorithm.knn",
        "peekOfCode": "def calculate_accuracy(actual_series, predicted_seires):\n    if (len(actual_series))==len((predicted_seires)):\n        # transform series to list\n        actual_list=np.array(actual_series.tolist())\n        # transform series to list & change datatype integer\n        predicted_list=np.array(predicted_seires, dtype=int)\n        # compare two column. matched->1, mismatched->0\n        match_count=np.sum(actual_list==predicted_list)\n        # calculate accuracy\n        accuracy_value=match_count/len(actual_list)",
        "detail": "knn_algorithm.knn",
        "documentation": {}
    },
    {
        "label": "calculate_f1score",
        "kind": 2,
        "importPath": "knn_algorithm.knn",
        "description": "knn_algorithm.knn",
        "peekOfCode": "def calculate_f1score(actual_series, predicted_series):\n    actual = np.array(actual_series.tolist(), dtype=int)\n    predicted = np.array(predicted_series.tolist(), dtype=int)\n    # TP, FP, FN ì •ì˜\n    TP = np.sum((actual == 1) & (predicted == 1))\n    FP = np.sum((actual == 0) & (predicted == 1))\n    FN = np.sum((actual == 1) & (predicted == 0))\n    # Precision, Recall ê³„ì‚°\n    precision = TP / (TP + FP) if (TP + FP) > 0 else 0\n    recall = TP / (TP + FN) if (TP + FN) > 0 else 0",
        "detail": "knn_algorithm.knn",
        "documentation": {}
    },
    {
        "label": "knn_algorithm",
        "kind": 2,
        "importPath": "knn_algorithm.knn",
        "description": "knn_algorithm.knn",
        "peekOfCode": "def knn_algorithm(k, test_euclidean, predicted_class, actual_class, data_info, try_count, accuracy_f1_table):\n    predicted_table=pd.DataFrame()\n    # Iterate over k values : 1~51 odd number\n    for k_num in range(1,k+1,2): \n        # j is for data instances \n        for test_num in range(len(test_euclidean.columns)):\n            # cutoff k amount and get indices\n            cutoff_indcies=cutoff_k(test_euclidean[\"Test_\"+str(test_num)],k_num)\n            # get predicted list \n            predicted_list=predicted_class.iloc[cutoff_indcies]",
        "detail": "knn_algorithm.knn",
        "documentation": {}
    },
    {
        "label": "accuracy_avg_std",
        "kind": 2,
        "importPath": "knn_algorithm.knn",
        "description": "knn_algorithm.knn",
        "peekOfCode": "def accuracy_avg_std(accuracy_f1_table, data_info):\n    # add mean and std bottom of the each column (same k, different try)\n    meanstd = accuracy_f1_table.agg(['mean', 'std'])\n    # merge accuracy_f1_table with std table \n    graph_table=pd.concat([accuracy_f1_table, meanstd])\n    print(\"graph_table\")\n    print(graph_table)\n    # message\n    print(\"\\n--> Calcuate mean and standard deviation of each k value : \"+str(data_info)+\"...\")\n    return graph_table",
        "detail": "knn_algorithm.knn",
        "documentation": {}
    },
    {
        "label": "draw_graph",
        "kind": 2,
        "importPath": "knn_algorithm.knn",
        "description": "knn_algorithm.knn",
        "peekOfCode": "def draw_graph(accuracy_f1_table, title):\n    # get only accuracy_table\n    accuracy_table=accuracy_f1_table[[col for col in accuracy_f1_table.columns if \"accuracy\" in col]]\n    # Extract integer k values from the column names using regex\n    k_values = []\n    for col in accuracy_table.columns:\n        match = re.search(r'\\(k=(\\d+)\\)', col)\n        if match:\n            k_values.append(int(match.group(1)))\n        else:",
        "detail": "knn_algorithm.knn",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "knn_algorithm.knn",
        "description": "knn_algorithm.knn",
        "peekOfCode": "def main():\n    train_accuracy=pd.DataFrame()\n    test_accuracy=pd.DataFrame()\n    data_file=load_data()\n    # iterate try = 1 ~ 20 \n    for try_count in range(1,ITERATION_COUNT+1):\n        # message\n        print(\"\\n================================================================================\")\n        print(f\"[[ try = {try_count} ]]\")\n        # preprocess dataset",
        "detail": "knn_algorithm.knn",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "neural_network.debug_text",
        "description": "neural_network.debug_text",
        "peekOfCode": "def main(lambda_reg, X, y, Theta, all_a_lists, all_z_lists, J_list, final_cost, delta_list, D_list, finalized_D, DEBUG_FILENAME, header=\"\"): \n    # Open a debug file for writing results\n    with open(f\"debug/backprop_{DEBUG_FILENAME}.txt\", \"w\", encoding=\"utf-8\") as f:\n        if header:\n            # Write optional header if provided\n            f.write(\"=\" * 80 + \"\\n\")\n            f.write(header + \"\\n\")\n            f.write(\"=\" * 80 + \"\\n\")\n        # Set NumPy printing options for consistent formatting\n        np.set_printoptions(precision=5, suppress=True, floatmode='fixed')",
        "detail": "neural_network.debug_text",
        "documentation": {}
    },
    {
        "label": "NeuralNetwork",
        "kind": 6,
        "importPath": "neural_network.nn",
        "description": "neural_network.nn",
        "peekOfCode": "class NeuralNetwork:\n    def __init__(self, layer_sizes, alpha=0.01, lambda_reg=0.0):\n        self.layer_sizes = layer_sizes  # Architecture of the network\n        self.alpha = alpha              # Learning rate\n        self.lambda_reg = lambda_reg    # Regularization parameter\n        self.weights = self.initialize_weights()  # Random weight initialization\n        self.cost_history = []          # Store J value per training set\n    def initialize_weights(self):\n        # Initialize weights for each layer using uniform distribution\n        weights = []",
        "detail": "neural_network.nn",
        "documentation": {}
    },
    {
        "label": "load_dataset",
        "kind": 2,
        "importPath": "neural_network.nn",
        "description": "neural_network.nn",
        "peekOfCode": "def load_dataset():\n    # Load dataset from CSV file\n    DATA_PATH = f\"../datasets/{DATASET_NAME}.csv\"\n    df = pd.read_csv(DATA_PATH)\n    # Use 'diagnosis' column if 'label' doesn't exist\n    if 'label' not in df.columns:\n        if 'Diagnosis' in df.columns:\n            df = df.rename(columns={'Diagnosis': 'label'})\n            print(\"ðŸ›ˆ Renamed 'Diagnosis' to 'label' for compatibility.\")\n        else:",
        "detail": "neural_network.nn",
        "documentation": {}
    },
    {
        "label": "stratified_k_fold_split",
        "kind": 2,
        "importPath": "neural_network.nn",
        "description": "neural_network.nn",
        "peekOfCode": "def stratified_k_fold_split(X, y, k=5):\n    # Create stratified folds with equal class distribution\n    df = pd.DataFrame(X)\n    df['label'] = y.ravel()\n    class_0 = df[df['label'] == 0].sample(frac=1).reset_index(drop=True)\n    class_1 = df[df['label'] == 1].sample(frac=1).reset_index(drop=True)\n    folds = []\n    for i in range(k):\n        c0 = class_0.iloc[int(len(class_0)*i/k):int(len(class_0)*(i+1)/k)]\n        c1 = class_1.iloc[int(len(class_1)*i/k):int(len(class_1)*(i+1)/k)]",
        "detail": "neural_network.nn",
        "documentation": {}
    },
    {
        "label": "my_accuracy",
        "kind": 2,
        "importPath": "neural_network.nn",
        "description": "neural_network.nn",
        "peekOfCode": "def my_accuracy(y_true, y_pred):\n    correct = np.sum(y_true == y_pred)\n    return correct / len(y_true)\n# === F1 Score Calculation ===\ndef my_f1_score(y_true, y_pred):\n    tp = np.sum((y_true == 1) & (y_pred == 1))\n    fp = np.sum((y_true == 0) & (y_pred == 1))\n    fn = np.sum((y_true == 1) & (y_pred == 0))\n    if tp == 0:\n        return 0.0",
        "detail": "neural_network.nn",
        "documentation": {}
    },
    {
        "label": "my_f1_score",
        "kind": 2,
        "importPath": "neural_network.nn",
        "description": "neural_network.nn",
        "peekOfCode": "def my_f1_score(y_true, y_pred):\n    tp = np.sum((y_true == 1) & (y_pred == 1))\n    fp = np.sum((y_true == 0) & (y_pred == 1))\n    fn = np.sum((y_true == 1) & (y_pred == 0))\n    if tp == 0:\n        return 0.0\n    precision = tp / (tp + fp) if (tp + fp) > 0 else 0.0\n    recall = tp / (tp + fn) if (tp + fn) > 0 else 0.0\n    if precision + recall == 0:\n        return 0.0",
        "detail": "neural_network.nn",
        "documentation": {}
    },
    {
        "label": "plot_best_learning_curve",
        "kind": 2,
        "importPath": "neural_network.nn",
        "description": "neural_network.nn",
        "peekOfCode": "def plot_best_learning_curve(results, dataset_name, save_folder):\n    # Identify model with lowest final cost\n    best_key = min(results, key=lambda k: results[k]['model'].cost_history[-1])\n    best_info = results[best_key]\n    model = best_info['model']\n    hidden_layer = best_info['hidden']\n    lambda_reg = best_info['lambda_reg']\n    train_size = best_info['train_size']\n    alpha = best_info['alpha']\n    mode = best_info['mode']",
        "detail": "neural_network.nn",
        "documentation": {}
    },
    {
        "label": "save_metrics_table",
        "kind": 2,
        "importPath": "neural_network.nn",
        "description": "neural_network.nn",
        "peekOfCode": "def save_metrics_table(results_by_dataset, save_folder):\n    os.makedirs(\"evaluation\", exist_ok=True)\n    for dataset_name, dataset_results in results_by_dataset.items():\n        fig, ax = plt.subplots()\n        ax.axis('off')\n        # Determine table columns based on whether mini-batch was used\n        if any(val['mode'] == 'mini-batch' for val in dataset_results.values()):\n            col_labels = [\"Layer & Neuron\", \"Lambda\", \"Alpha\", \"Batch Size\", \"Mode\", \"Avg Accuracy\", \"Avg F1 Score\"]\n            show_batch_size = True\n        else:",
        "detail": "neural_network.nn",
        "documentation": {}
    },
    {
        "label": "neural_network",
        "kind": 2,
        "importPath": "neural_network.nn",
        "description": "neural_network.nn",
        "peekOfCode": "def neural_network():\n    X, y = load_dataset()  # Load data and labels\n    folds = stratified_k_fold_split(X, y, k=5)  # Create 5-fold split\n    lambda_reg_list = [0.1, 0.000001]  # List of Î» values to test\n    hidden_layers = [[32], [32, 16], [32, 16, 8], [32, 16, 8, 4]]  # Layer architectures to test\n    alpha = ALPHA            # Learning rate\n    batch_size = BATCH_SIZE        # Size of mini-batches\n    mode = TRAIN_MODE        # Training mode\n    dataset_name = DATASET_NAME\n    results = {}  # Dictionary to collect evaluation metrics",
        "detail": "neural_network.nn",
        "documentation": {}
    },
    {
        "label": "DATASET_NAME",
        "kind": 5,
        "importPath": "neural_network.nn",
        "description": "neural_network.nn",
        "peekOfCode": "DATASET_NAME = \"digits\"  # Name of the dataset\nDEBUG_MODE = True         # If True, run debugging routine at the end\nTRAIN_MODE = \"mini-batch\"    # Choose \"batch\" or \"mini-batch\"\nBATCH_SIZE = 64\nALPHA=0.1\n# === Stopping Criteria ===\nSTOP_CRITERIA = \"M\"\nM_SIZE = 50            \nJ_SIZE=0.1\n# === FILE_NAME Setting ===",
        "detail": "neural_network.nn",
        "documentation": {}
    },
    {
        "label": "DEBUG_MODE",
        "kind": 5,
        "importPath": "neural_network.nn",
        "description": "neural_network.nn",
        "peekOfCode": "DEBUG_MODE = True         # If True, run debugging routine at the end\nTRAIN_MODE = \"mini-batch\"    # Choose \"batch\" or \"mini-batch\"\nBATCH_SIZE = 64\nALPHA=0.1\n# === Stopping Criteria ===\nSTOP_CRITERIA = \"M\"\nM_SIZE = 50            \nJ_SIZE=0.1\n# === FILE_NAME Setting ===\nif TRAIN_MODE==\"batch\":",
        "detail": "neural_network.nn",
        "documentation": {}
    },
    {
        "label": "TRAIN_MODE",
        "kind": 5,
        "importPath": "neural_network.nn",
        "description": "neural_network.nn",
        "peekOfCode": "TRAIN_MODE = \"mini-batch\"    # Choose \"batch\" or \"mini-batch\"\nBATCH_SIZE = 64\nALPHA=0.1\n# === Stopping Criteria ===\nSTOP_CRITERIA = \"M\"\nM_SIZE = 50            \nJ_SIZE=0.1\n# === FILE_NAME Setting ===\nif TRAIN_MODE==\"batch\":\n    FILE_NAME = DATASET_NAME",
        "detail": "neural_network.nn",
        "documentation": {}
    },
    {
        "label": "BATCH_SIZE",
        "kind": 5,
        "importPath": "neural_network.nn",
        "description": "neural_network.nn",
        "peekOfCode": "BATCH_SIZE = 64\nALPHA=0.1\n# === Stopping Criteria ===\nSTOP_CRITERIA = \"M\"\nM_SIZE = 50            \nJ_SIZE=0.1\n# === FILE_NAME Setting ===\nif TRAIN_MODE==\"batch\":\n    FILE_NAME = DATASET_NAME\nelif TRAIN_MODE==\"mini-batch\":",
        "detail": "neural_network.nn",
        "documentation": {}
    },
    {
        "label": "STOP_CRITERIA",
        "kind": 5,
        "importPath": "neural_network.nn",
        "description": "neural_network.nn",
        "peekOfCode": "STOP_CRITERIA = \"M\"\nM_SIZE = 50            \nJ_SIZE=0.1\n# === FILE_NAME Setting ===\nif TRAIN_MODE==\"batch\":\n    FILE_NAME = DATASET_NAME\nelif TRAIN_MODE==\"mini-batch\":\n    FILE_NAME = DATASET_NAME+\"_minibatch\"\nelse:\n    print(\"choose mini-batch or batch in TRAIN_MODE\")",
        "detail": "neural_network.nn",
        "documentation": {}
    },
    {
        "label": "M_SIZE",
        "kind": 5,
        "importPath": "neural_network.nn",
        "description": "neural_network.nn",
        "peekOfCode": "M_SIZE = 50            \nJ_SIZE=0.1\n# === FILE_NAME Setting ===\nif TRAIN_MODE==\"batch\":\n    FILE_NAME = DATASET_NAME\nelif TRAIN_MODE==\"mini-batch\":\n    FILE_NAME = DATASET_NAME+\"_minibatch\"\nelse:\n    print(\"choose mini-batch or batch in TRAIN_MODE\")\n# === Neural Network Class ===",
        "detail": "neural_network.nn",
        "documentation": {}
    },
    {
        "label": "sigmoid",
        "kind": 2,
        "importPath": "neural_network.propagation",
        "description": "neural_network.propagation",
        "peekOfCode": "def sigmoid(z):\n    return 1 / (1 + np.exp(-z))\ndef sigmoid_gradient(z):\n    return sigmoid(z) * (1 - sigmoid(z))\ndef add_bias(X):\n    return np.concatenate([np.ones((X.shape[0], 1)), X], axis=1)\ndef forward_propagation(Theta, X):\n    Theta = [np.array(t) for t in Theta]\n    A = [add_bias(np.array(X))] \n    Z = []",
        "detail": "neural_network.propagation",
        "documentation": {}
    },
    {
        "label": "sigmoid_gradient",
        "kind": 2,
        "importPath": "neural_network.propagation",
        "description": "neural_network.propagation",
        "peekOfCode": "def sigmoid_gradient(z):\n    return sigmoid(z) * (1 - sigmoid(z))\ndef add_bias(X):\n    return np.concatenate([np.ones((X.shape[0], 1)), X], axis=1)\ndef forward_propagation(Theta, X):\n    Theta = [np.array(t) for t in Theta]\n    A = [add_bias(np.array(X))] \n    Z = []\n    for i, Theta_i in enumerate(Theta):\n        Z_i = A[-1] @ Theta_i.T",
        "detail": "neural_network.propagation",
        "documentation": {}
    },
    {
        "label": "add_bias",
        "kind": 2,
        "importPath": "neural_network.propagation",
        "description": "neural_network.propagation",
        "peekOfCode": "def add_bias(X):\n    return np.concatenate([np.ones((X.shape[0], 1)), X], axis=1)\ndef forward_propagation(Theta, X):\n    Theta = [np.array(t) for t in Theta]\n    A = [add_bias(np.array(X))] \n    Z = []\n    for i, Theta_i in enumerate(Theta):\n        Z_i = A[-1] @ Theta_i.T\n        A_i = sigmoid(Z_i)\n        Z.append(Z_i)",
        "detail": "neural_network.propagation",
        "documentation": {}
    },
    {
        "label": "forward_propagation",
        "kind": 2,
        "importPath": "neural_network.propagation",
        "description": "neural_network.propagation",
        "peekOfCode": "def forward_propagation(Theta, X):\n    Theta = [np.array(t) for t in Theta]\n    A = [add_bias(np.array(X))] \n    Z = []\n    for i, Theta_i in enumerate(Theta):\n        Z_i = A[-1] @ Theta_i.T\n        A_i = sigmoid(Z_i)\n        Z.append(Z_i)\n        if i < len(Theta) - 1:\n            A_i = add_bias(A_i) # add bias in hidden layer only",
        "detail": "neural_network.propagation",
        "documentation": {}
    },
    {
        "label": "cost_function",
        "kind": 2,
        "importPath": "neural_network.propagation",
        "description": "neural_network.propagation",
        "peekOfCode": "def cost_function(A_final, Y, Theta, lambda_reg):\n    m = Y.shape[0]\n    cost = -np.sum(Y * np.log(A_final) + (1 - Y) * np.log(1 - A_final)) / m\n    reg_term = 0\n    for theta in Theta:\n        theta = np.array(theta)\n        # remove bias -> [:, 1:]\n        reg_term += np.sum(theta[:, 1:] ** 2) \n    reg_term = reg_term * (lambda_reg / (2 * m))\n    return cost, cost + reg_term",
        "detail": "neural_network.propagation",
        "documentation": {}
    },
    {
        "label": "backpropagation_vectorized",
        "kind": 2,
        "importPath": "neural_network.propagation",
        "description": "neural_network.propagation",
        "peekOfCode": "def backpropagation_vectorized(Theta, A, Z, Y, lambda_reg):\n    Theta = [np.array(t) for t in Theta]\n    m = Y.shape[0]\n    delta = A[-1] - Y\n    gradients = [None] * len(Theta)\n    for i in reversed(range(len(Theta))):\n        a_prev = A[i]\n        gradients[i] = (delta.T @ a_prev) / m\n        if i > 0:\n            delta = (delta @ Theta[i][:, 1:]) * sigmoid_gradient(Z[i - 1])",
        "detail": "neural_network.propagation",
        "documentation": {}
    },
    {
        "label": "run_debug",
        "kind": 2,
        "importPath": "neural_network.propagation",
        "description": "neural_network.propagation",
        "peekOfCode": "def run_debug(Theta, X, y, lambda_reg, DEBUG_FILENAME):\n    np.set_printoptions(precision=5, suppress=True, floatmode='fixed')\n    A, Z, all_a_lists, all_z_lists = forward_propagation(Theta, X)\n    pred_y_list = [a_list[-1] for a_list in all_a_lists]\n    true_y_list = [y[i].reshape(-1, 1) for i in range(y.shape[0])]\n    J_list = []\n    for pred, true in zip(pred_y_list, true_y_list):\n        J = -(true.T @ np.log(pred) + (1 - true).T @ np.log(1 - pred))\n        J_list.append(J.item())\n    delta_list = []",
        "detail": "neural_network.propagation",
        "documentation": {}
    },
    {
        "label": "Node",
        "kind": 6,
        "importPath": "random_forest.tree",
        "description": "random_forest.tree",
        "peekOfCode": "class Node:\n    # Node in the decision tree\n    def __init__(self, feature=None, threshold=None, label=None, children=None):\n        self.feature = feature\n        self.threshold = threshold\n        self.label = label\n        self.children = children if children else {}\n# Compute entropy of label distribution\n# e.g., (x=sunny)-> y = [y,y,y,n,n] -> entropy calcuate\n# e.g., all y = [y,y,y,n,n,n,n,n,y,y,y,n] -> entropy calcuate",
        "detail": "random_forest.tree",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "random_forest.tree",
        "description": "random_forest.tree",
        "peekOfCode": "def main():\n    ##### choose dataset #####\n    filename = f\"../datasets/{DATASET_NAME}.csv\" # <<<<===== changing point \n    base = os.path.basename(filename)     \n    basename = os.path.splitext(base)[0]\n    # Load dataset and preprocess it\n    data = load_and_preprocess_data(filename)\n    # Apply stratified k-fold cross-validation\n    fold_data = cross_validation(data, k_fold=5)\n    # Train and evaluate Random Forest",
        "detail": "random_forest.tree",
        "documentation": {}
    },
    {
        "label": "load_and_preprocess_data",
        "kind": 2,
        "importPath": "random_forest.tree",
        "description": "random_forest.tree",
        "peekOfCode": "def load_and_preprocess_data(filepath):\n    # Load CSV and rename target column\n    data = pd.read_csv(filepath)\n    data = data.rename(columns={\"class\": \"label\"})\n    # Process each column by its suffix\n    for col in data.columns:\n        if col == \"label\":\n            continue\n        elif col.endswith(\"_cat\"):\n            data[col] = data[col].astype(str)  # Categorical feature",
        "detail": "random_forest.tree",
        "documentation": {}
    },
    {
        "label": "cross_validation",
        "kind": 2,
        "importPath": "random_forest.tree",
        "description": "random_forest.tree",
        "peekOfCode": "def cross_validation(data, k_fold):\n    # Separate data by class label for stratified sampling\n    class_0 = data[data['label'] == 0].sample(frac=1).reset_index(drop=True) # sampling with fraction=100%\n    class_1 = data[data['label'] == 1].sample(frac=1).reset_index(drop=True) # sampling with fraction=100%\n    # proceed seperate class_0(label=0 sub dataset), class_1(label=1 sub dataset) to preserve proportions\n    all_data = pd.DataFrame()\n    for i in range(k_fold):\n        # Slice each class proportionally into folds => satisfied disjoint condition \n        class_0_start = int(len(class_0) * i / k_fold)\n        class_0_end = int(len(class_0) * (i + 1) / k_fold)",
        "detail": "random_forest.tree",
        "documentation": {}
    },
    {
        "label": "bootstrap_sample",
        "kind": 2,
        "importPath": "random_forest.tree",
        "description": "random_forest.tree",
        "peekOfCode": "def bootstrap_sample(X, y):\n    # random select on index\n    idxs = np.random.choice(len(X), size=len(X), replace=True) # replacement = True\n    # get the selected index in X,y\n    X_sample = X.iloc[idxs].reset_index(drop=True)\n    y_sample = y.iloc[idxs].reset_index(drop=True)\n    # return same as input\n    return X_sample, y_sample\n# ===== Evaluation & Plotting =====\ndef evaluate_random_forest(fold_data, k_fold, basename):",
        "detail": "random_forest.tree",
        "documentation": {}
    },
    {
        "label": "evaluate_random_forest",
        "kind": 2,
        "importPath": "random_forest.tree",
        "description": "random_forest.tree",
        "peekOfCode": "def evaluate_random_forest(fold_data, k_fold, basename):\n    ntrees_list = [1, 5, 10, 20, 30, 40, 50]\n    acc_list, prec_list, rec_list, f1_list = [], [], [], []\n    # operate in all ntrees\n    for ntrees in ntrees_list:\n        print(f\"\\nEvaluating Random Forest with {ntrees} trees\")\n        accs, precisions, recalls, f1s = [], [], [], []\n        # execute cross_validation\n        for i in range(k_fold):\n            # Split fold into training and testing",
        "detail": "random_forest.tree",
        "documentation": {}
    },
    {
        "label": "entropy",
        "kind": 2,
        "importPath": "random_forest.tree",
        "description": "random_forest.tree",
        "peekOfCode": "def entropy(y):\n    # count label and change to series\n    class_counts = y.value_counts()\n    # divided by total length\n    probabilities = class_counts / len(y)\n    # entropy = sum(- prob * log2(prob))\n    return -np.sum(probabilities * np.log2(probabilities))\ndef build_tree(X, y, features, depth=0):\n    ####### Stop splitting node criteria (maximal_depth and minimal_gain are combined) ####### \n    # depth = 0 --> check current node depth to confirm when depth reached to max_depth",
        "detail": "random_forest.tree",
        "documentation": {}
    },
    {
        "label": "build_tree",
        "kind": 2,
        "importPath": "random_forest.tree",
        "description": "random_forest.tree",
        "peekOfCode": "def build_tree(X, y, features, depth=0):\n    ####### Stop splitting node criteria (maximal_depth and minimal_gain are combined) ####### \n    # depth = 0 --> check current node depth to confirm when depth reached to max_depth\n    max_depth=5 # maximal_depth\n    min_info_gain=1e-5 # minimal_gain\n    ### Check Stop Spliting condition ===> maximal_depth\n    # unique -> check all the same class\n    # len(features) -> no features left\n    # current depth = max_depth\n    if len(y.unique()) == 1 or len(features) == 0 or depth == max_depth:",
        "detail": "random_forest.tree",
        "documentation": {}
    },
    {
        "label": "random_forest_predict",
        "kind": 2,
        "importPath": "random_forest.tree",
        "description": "random_forest.tree",
        "peekOfCode": "def random_forest_predict(trees, X_test):\n    # Collect predictions from all trees (shape: [num_trees, num_X_test_samples])\n    # k-fold function result => test dataset fixed\n    # test sample : 3, tree: 4 => [[1,0,0],[1,1,1],[0,1,1],[1,1,1]]\n    tree_preds = np.array([predict(tree, X_test) for tree in trees])\n    # Total number of test samples\n    test_all = X_test.shape[0]  \n    # List to store final predictions after majority voting\n    final_preds = [] \n    # Iterate over each sample",
        "detail": "random_forest.tree",
        "documentation": {}
    },
    {
        "label": "predict",
        "kind": 2,
        "importPath": "random_forest.tree",
        "description": "random_forest.tree",
        "peekOfCode": "def predict(tree, X_test):\n    # gather all the prediction results\n    predictions = []\n    ##### repeat X_test counts #####\n    # get index(not using), row(samples) from itterows\n    for index, row in X_test.iterrows(): # iterate row by row\n        # initialize the node = tree\n        # each sample starts to search from root of tree\n        node = tree\n        # repeat until reaching out to the leaf node (label exist -> leaf node)",
        "detail": "random_forest.tree",
        "documentation": {}
    },
    {
        "label": "accuracy",
        "kind": 2,
        "importPath": "random_forest.tree",
        "description": "random_forest.tree",
        "peekOfCode": "def accuracy(predictions, true_labels):\n    predictions = np.array(predictions)\n    true_labels = np.array(true_labels)\n    valid = predictions != None\n    return np.mean(predictions[valid] == true_labels[valid])\n# Calculate precision\ndef precision(y_true, y_pred):\n    tp = np.sum((y_pred == 1) & (y_true == 1))\n    fp = np.sum((y_pred == 1) & (y_true == 0))\n    return tp / (tp + fp) if (tp + fp) > 0 else 0.0",
        "detail": "random_forest.tree",
        "documentation": {}
    },
    {
        "label": "precision",
        "kind": 2,
        "importPath": "random_forest.tree",
        "description": "random_forest.tree",
        "peekOfCode": "def precision(y_true, y_pred):\n    tp = np.sum((y_pred == 1) & (y_true == 1))\n    fp = np.sum((y_pred == 1) & (y_true == 0))\n    return tp / (tp + fp) if (tp + fp) > 0 else 0.0\n# Calculate recall\ndef recall(y_true, y_pred):\n    tp = np.sum((y_pred == 1) & (y_true == 1))\n    fn = np.sum((y_pred == 0) & (y_true == 1))\n    return tp / (tp + fn) if (tp + fn) > 0 else 0.0\n# Calculate F1-score",
        "detail": "random_forest.tree",
        "documentation": {}
    },
    {
        "label": "recall",
        "kind": 2,
        "importPath": "random_forest.tree",
        "description": "random_forest.tree",
        "peekOfCode": "def recall(y_true, y_pred):\n    tp = np.sum((y_pred == 1) & (y_true == 1))\n    fn = np.sum((y_pred == 0) & (y_true == 1))\n    return tp / (tp + fn) if (tp + fn) > 0 else 0.0\n# Calculate F1-score\ndef f1_score_manual(y_true, y_pred):\n    p = precision(y_true, y_pred)\n    r = recall(y_true, y_pred)\n    return 2 * p * r / (p + r) if (p + r) > 0 else 0.0\n##################################### plot the metrics ##################################### ",
        "detail": "random_forest.tree",
        "documentation": {}
    },
    {
        "label": "f1_score_manual",
        "kind": 2,
        "importPath": "random_forest.tree",
        "description": "random_forest.tree",
        "peekOfCode": "def f1_score_manual(y_true, y_pred):\n    p = precision(y_true, y_pred)\n    r = recall(y_true, y_pred)\n    return 2 * p * r / (p + r) if (p + r) > 0 else 0.0\n##################################### plot the metrics ##################################### \ndef plot_metrics(basename, ntrees_list, metrics, save_dir):\n    titles = [\"Accuracy\", \"Precision\", \"Recall\", \"F1Score\"]\n    os.makedirs(save_dir, exist_ok=True)\n    for metric, title in zip(metrics, titles):\n        plt.figure(figsize=(6, 4))",
        "detail": "random_forest.tree",
        "documentation": {}
    },
    {
        "label": "plot_metrics",
        "kind": 2,
        "importPath": "random_forest.tree",
        "description": "random_forest.tree",
        "peekOfCode": "def plot_metrics(basename, ntrees_list, metrics, save_dir):\n    titles = [\"Accuracy\", \"Precision\", \"Recall\", \"F1Score\"]\n    os.makedirs(save_dir, exist_ok=True)\n    for metric, title in zip(metrics, titles):\n        plt.figure(figsize=(6, 4))\n        plt.plot(ntrees_list, metric, marker='o')\n        plt.title(f\"{basename.capitalize()} Dataset_{title} vs ntrees\")\n        plt.xlabel(\"ntrees\")\n        plt.ylabel(title)\n        plt.grid(True)",
        "detail": "random_forest.tree",
        "documentation": {}
    },
    {
        "label": "tree_to_dict",
        "kind": 2,
        "importPath": "random_forest.tree",
        "description": "random_forest.tree",
        "peekOfCode": "def tree_to_dict(node):\n    if node.label is not None:\n        return {\"label\": int(node.label)}\n    return {\n        \"feature\": node.feature,\n        \"threshold\": node.threshold,\n        \"children\": {str(k): tree_to_dict(v) for k, v in node.children.items()}\n    }\n# Save all trees in the forest as JSON files\ndef save_trees_as_json(trees, ntrees, base_dir=\"saved_trees\"):",
        "detail": "random_forest.tree",
        "documentation": {}
    },
    {
        "label": "save_trees_as_json",
        "kind": 2,
        "importPath": "random_forest.tree",
        "description": "random_forest.tree",
        "peekOfCode": "def save_trees_as_json(trees, ntrees, base_dir=\"saved_trees\"):\n    folder = os.path.join(base_dir, f\"ntrees_{ntrees}\")\n    os.makedirs(folder, exist_ok=True)\n    for i, tree in enumerate(trees, start=1):\n        tree_dict = tree_to_dict(tree)\n        with open(os.path.join(folder, f\"tree_{i}.json\"), \"w\") as f:\n            json.dump(tree_dict, f, indent=4)\nif __name__ == \"__main__\":\n    main()",
        "detail": "random_forest.tree",
        "documentation": {}
    },
    {
        "label": "Node",
        "kind": 6,
        "importPath": "digits_decisiontree",
        "description": "digits_decisiontree",
        "peekOfCode": "class Node:\n    def __init__(self, feature=None, label=None, children=None):\n        self.feature = feature\n        self.label = label\n        self.children = children if children else {}\n# Build decision tree function\ndef build_tree(X, y, features):\n    if len(y.unique()) == 1:\n        return Node(label=y.iloc[0])\n    if len(features) == 0:",
        "detail": "digits_decisiontree",
        "documentation": {}
    },
    {
        "label": "load_data",
        "kind": 2,
        "importPath": "digits_decisiontree",
        "description": "digits_decisiontree",
        "peekOfCode": "def load_data():\n    # Load the digits dataset\n    digits = datasets.load_digits()\n    X = digits.data\n    y = digits.target\n    # Fix here: set correct column name\n    X_df = pd.DataFrame(X)\n    y_df = pd.DataFrame(y, columns=['class'])\n    print(X_df)\n    print(y_df)",
        "detail": "digits_decisiontree",
        "documentation": {}
    },
    {
        "label": "gini_impurity",
        "kind": 2,
        "importPath": "digits_decisiontree",
        "description": "digits_decisiontree",
        "peekOfCode": "def gini_impurity(y):\n    class_counts = y.value_counts()\n    probabilities = class_counts / len(y)\n    return 1 - np.sum(probabilities ** 2)\n# Gini impurity reduction calculation function (Information Gain â†’ Gini Reduction)\ndef gini_reduction(X, y, feature):\n    total_gini = gini_impurity(y)\n    values = X[feature].unique()\n    weighted_gini = sum(\n        (len(y[X[feature] == value]) / len(y)) * gini_impurity(y[X[feature] == value]) for value in values",
        "detail": "digits_decisiontree",
        "documentation": {}
    },
    {
        "label": "gini_reduction",
        "kind": 2,
        "importPath": "digits_decisiontree",
        "description": "digits_decisiontree",
        "peekOfCode": "def gini_reduction(X, y, feature):\n    total_gini = gini_impurity(y)\n    values = X[feature].unique()\n    weighted_gini = sum(\n        (len(y[X[feature] == value]) / len(y)) * gini_impurity(y[X[feature] == value]) for value in values\n    )\n    return total_gini - weighted_gini\n# Decision tree node class\nclass Node:\n    def __init__(self, feature=None, label=None, children=None):",
        "detail": "digits_decisiontree",
        "documentation": {}
    },
    {
        "label": "build_tree",
        "kind": 2,
        "importPath": "digits_decisiontree",
        "description": "digits_decisiontree",
        "peekOfCode": "def build_tree(X, y, features):\n    if len(y.unique()) == 1:\n        return Node(label=y.iloc[0])\n    if len(features) == 0:\n        return Node(label=y.mode()[0])\n    # Choose the best feature based on Gini Reduction\n    best_feature = max(features, key=lambda f: gini_reduction(X, y, f))\n    tree = Node(feature=best_feature)\n    remaining_features = [f for f in features if f != best_feature]\n    for value in X[best_feature].unique():",
        "detail": "digits_decisiontree",
        "documentation": {}
    },
    {
        "label": "tree_to_dict",
        "kind": 2,
        "importPath": "digits_decisiontree",
        "description": "digits_decisiontree",
        "peekOfCode": "def tree_to_dict(tree):\n    if tree.label is not None:\n        return {'label': int(tree.label)}  # ðŸ”¥ í•µì‹¬ ìˆ˜ì •\n    return {\n        'feature': tree.feature,\n        'children': {str(value): tree_to_dict(child) for value, child in tree.children.items()}\n    }\n# Predict function\ndef predict(tree, X):\n    predictions = []",
        "detail": "digits_decisiontree",
        "documentation": {}
    },
    {
        "label": "predict",
        "kind": 2,
        "importPath": "digits_decisiontree",
        "description": "digits_decisiontree",
        "peekOfCode": "def predict(tree, X):\n    predictions = []\n    for _, row in X.iterrows():\n        node = tree\n        while node.label is None:\n            if row[node.feature] not in node.children:\n                predictions.append(None)\n                break\n            node = node.children[row[node.feature]]\n        else:",
        "detail": "digits_decisiontree",
        "documentation": {}
    },
    {
        "label": "evaluate",
        "kind": 2,
        "importPath": "digits_decisiontree",
        "description": "digits_decisiontree",
        "peekOfCode": "def evaluate(X, y, test_size=0.2, num_trials=100):\n    train_accuracies = []\n    test_accuracies = []\n    for trial in range(1, num_trials + 1):\n        print(f\"Running trial {trial}...\")\n        # shuffle for every trial\n        df_shuffled = shuffle(pd.concat([X, y], axis=1), random_state=None)\n        X_shuffled = df_shuffled.drop(columns=['class'])\n        y_shuffled = df_shuffled['class']\n        # Train-test split",
        "detail": "digits_decisiontree",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "digits_decisiontree",
        "description": "digits_decisiontree",
        "peekOfCode": "def main():\n    # Load dataset (shuffle X)\n    X,y=load_data()\n    # Run evaluation (shuffle for every trial)\n    train_acc, test_acc = evaluate(X, y, test_size=0.2, num_trials=100)\n    # Plot histograms\n    plt.figure(figsize=(6, 4))\n    plt.hist(train_acc, bins=10, edgecolor='black', alpha=0.7)\n    plt.xlabel('Training Accuracy')\n    plt.ylabel('Accuracy Frequency on Training Data')",
        "detail": "digits_decisiontree",
        "documentation": {}
    }
]